{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN-base.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PRaezUC3M/cohort_selection/blob/master/CNN_base.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "LkVRZSWTfdg2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This notebook is backed with github.\n",
        "https://github.com/PRaezUC3M/cohort_selection/"
      ]
    },
    {
      "metadata": {
        "id": "VUhjUt2_2taj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Mount the drive folder**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KX7MO6oMrqR4",
        "outputId": "bc2ea52f-5397-4e39-95c7-cf914c4d3220",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vluB44afpEHL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Configurartion of the experiments**\n",
        "The different possible experiments have been automated. It is inspired in grid-search, and the parameters must be expressed in array-like style. You can find an example below.\n",
        "\n",
        "Every possible example will be generated from the combination of the different parameters given."
      ]
    },
    {
      "metadata": {
        "id": "dvpLzS-wneo4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "np.random.seed(1)\n",
        "tf.set_random_seed(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AdJIJMn1pbCa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Baseline Model\n",
        "oversampling = [False]\n",
        "load_embeddings = [True, False] # This defines if the embeddings are loaded from the wikipedia dataset\n",
        "num_classes = [None] # Auto\n",
        "embeddings_size = [200]\n",
        "conv_size = [[128]] #[[64, 64, 128, 128, 256, 256]]\n",
        "conv_filter = [[10]]\n",
        "dropout = [0.1]\n",
        "fnn_size = [[64,13]]# [[256, 128, 128, 64]]\n",
        "batch_size = [32]\n",
        "\n",
        "indexes = [\"oversampling\", \"load_embeddings\", \"num_classes\", \"embeddings_size\", \"conv_size\", \"conv_filter\", \"dropout\", \"fnn_size\", \"batch_size\"]\n",
        "param   = [oversampling, load_embeddings, num_classes, embeddings_size, conv_size, conv_filter, dropout, fnn_size, batch_size]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b65TBRSg3wep",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "def combine_params(param, indexes):\n",
        "  combinations = list(itertools.product(*param))\n",
        "  param_combinations = [{k:v for k, v in zip(indexes, combination)}  for combination in combinations]\n",
        "  for p in param_combinations:\n",
        "    # The embeddings size must adapt to the embeddings loaded.\n",
        "    if p[\"load_embeddings\"]:\n",
        "      p[\"embeddings_size\"] = None\n",
        "  return param_combinations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N-nFuYPyy8eW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "network_parameters = combine_params(param, indexes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "P6yvcz6sqM16"
      },
      "cell_type": "markdown",
      "source": [
        "# **Load the train and test csv files**\n",
        "This functions load the data and generate the different datasets from the given csv files. "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "w0NdWd-SqM18",
        "outputId": "52be3295-988f-4bff-ae26-5950b4f5a4fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "SST_HOME='drive/My Drive/Colab Notebooks/CohortSelection/'\n",
        "path_train=SST_HOME+'data/train/train.csv'\n",
        "path_test=SST_HOME+'data/test/test.csv'\n",
        "\n",
        "def load(path):\n",
        "  \n",
        "  df = pd.read_csv(path,header=0, delimiter=\"\\t\", quoting=3)\n",
        "\n",
        "  categories=df.columns[2:];\n",
        "\n",
        "  idFiles = df[['IDFILE']].as_matrix().tolist()\n",
        "\n",
        "  texts = df[['TEXT']].as_matrix()\n",
        "  X = [x[0].strip() for x in texts.tolist()]\n",
        "\n",
        "  #we only keep the columns with the categories.\n",
        "  Y = df.drop(['IDFILE', 'TEXT'], axis=1).as_matrix()\n",
        "\n",
        "\n",
        "  print(path,'dataset loaded')\n",
        "  \n",
        "  return X, Y, categories, idFiles\n",
        "\n",
        "\n",
        "train_x, train_y, CATEGORIES, _ = load(path_train)\n",
        "test_x, test_y, _, IDFILES = load(path_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive/My Drive/Colab Notebooks/CohortSelection/data/train/train.csv dataset loaded\n",
            "drive/My Drive/Colab Notebooks/CohortSelection/data/test/test.csv dataset loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tqzBWeLFqiAW",
        "colab_type": "code",
        "outputId": "fc8efd29-d4ca-43b3-eea8-6b0ec6a12ab1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "train_y[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "zswqSRmTqM2A"
      },
      "cell_type": "markdown",
      "source": [
        "#**Balancing the categories**\n",
        "We can see that there are some categories way more present than others in our dataset. Let's sort them."
      ]
    },
    {
      "metadata": {
        "id": "OXBDCgcT8c5Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The categories are distributed in the following way\n"
      ]
    },
    {
      "metadata": {
        "id": "R9zxnXt38hO-",
        "colab_type": "code",
        "outputId": "fa963232-c88b-4047-bec0-95888ea8ea71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns  \n",
        "\n",
        "fig = plt.figure(figsize=(20,8))\n",
        "(ax_train, ax_test) = fig.subplots(ncols=2, nrows=1)\n",
        "g1 = sns.barplot(x=train_y.sum(axis=0), y=CATEGORIES, ax=ax_train)\n",
        "ax_train.set_xlabel('Number of records')\n",
        "g2 = sns.barplot(x=test_y.sum(axis=0), y=CATEGORIES, ax=ax_test)\n",
        "ax_test.set_xlabel('Number of records')\n",
        "g1.set_title(\"Criteria distribution on training dataset\")\n",
        "g2.set_title(\"Criteria distribution on testing dataset\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/categorical.py:1428: FutureWarning: remove_na is deprecated and is a private function. Do not use.\n",
            "  stat_data = remove_na(group_data)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5,1,'Criteria distribution on testing dataset')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABM8AAAHvCAYAAABDg/hfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA9pzREYE64/AAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f06ff15f438>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "7Bfd-GpbqM2G"
      },
      "cell_type": "markdown",
      "source": [
        "Now we can see the differences in a easier way, we will add weights to the different classes, based on how present they are in the dataset."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wQaO6I_tqM2H",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classes = np.add(sum(train_y), sum(test_y))\n",
        "total_cases = sum(classes)\n",
        "class_weight = [1 / (c/total_cases) for c in classes]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "jkLOdF0BqM2M"
      },
      "cell_type": "markdown",
      "source": [
        "# **Tokenize the dataset and use the word embeddings**\n",
        "\n",
        "This shows the set of different words ordered by frequency. *tokenizer.word_index*\n",
        "\n",
        "The text is tokenized and cleaned of stop-words as well as punctuation signs. Also the numbers are substituted by a token \"nmbr\"\n",
        "\n",
        "We crop the beggining of the examples because it is the date when they\n",
        "were written down.\n",
        "\n",
        "Finally, and after being tokenized, the different sentences are padded to match the maximum length.\n",
        "\n",
        "max_length == 7813 it is really a huge vector because we have to pad\n",
        "it afterwards, in order to get it into the CNN"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "3757a024-e420-4f4d-dadd-f2501edda63f",
        "id": "H9eO6C8wqM2M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words=stopwords.words('english')\n",
        "# Define maximum word length\n",
        "MAX_WORDS = 5000\n",
        "# Defined from the dataset itself.\n",
        "DATE_LENGTH = 23"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "RexMW528qM2R",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# We are using this function to clean the test set\n",
        "def tokenize_clean_text(text, tokenizer=None, max_length=None, \n",
        "                        max_words=MAX_WORDS, date_length=DATE_LENGTH):\n",
        "  \"\"\"\n",
        "  This function is in charge of tokenizing the text it is given. It also cleans\n",
        "  the text from stop-words, punctuation, and gives a special token to numbers.\n",
        "  \n",
        "  :param text: The texts to tokenize in a bidimensional python array.\n",
        "  \n",
        "  :returns: The tokenized and cleaned text in a bidimensional python array.\n",
        "            The tokenizer used to preprocess the text.\n",
        "            The maximum length used for padding.\n",
        "  \"\"\"  \n",
        "  # Consider to stemm or lemmatize the text \n",
        "  \n",
        "  cropped_date_text = [sentence[date_length:] for sentence in text]\n",
        "\n",
        "  if max_length == None:\n",
        "    # We get the maximum token length by splitting by spaces\n",
        "    max_length = max([len(sentence[date_length:].split(\" \")) for sentence in cropped_date_text])\n",
        "    \n",
        "  # We remove the numbers\n",
        "  cropped_date_numbers_text = [\" \".join([word if not word.isdigit() else \"\"\n",
        "                                for word in sentence.split()])\n",
        "                               for sentence in cropped_date_text]\n",
        "  \n",
        "  # Delete stopwords as well as every word less than 3 chars.\n",
        "  cropped_date_numbers_stopw_text = [\" \".join([word if not (word in stop_words or len(word) <= 3) else \"\"\n",
        "                                      for word in sentence.split()])\n",
        "                                     for sentence in cropped_date_numbers_text]\n",
        "  \n",
        "  if tokenizer is None:\n",
        "    tokenizer = Tokenizer(num_words=MAX_WORDS) # They use 5k words too\n",
        "    tokenizer.fit_on_texts(cropped_date_numbers_stopw_text)\n",
        "  # We tokenize the sentences\n",
        "  tokenized_text = tokenizer.texts_to_sequences(cropped_date_numbers_stopw_text)\n",
        "  \n",
        "  # Now we return the padded the sequences.\n",
        "  return pad_sequences(tokenized_text, max_length), tokenizer, max_length\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "4LeXd0Z0qM2U"
      },
      "cell_type": "markdown",
      "source": [
        "# **Oversampling**\n",
        "\n",
        "As the dataset is very unbalanced, we must perform over-sampling (which is to increase the minority class(es)). The RandomOverSampler **class** allows us to over-sample minority classes by  picking samples at random with replacement. We need to install the package **imbalanced-learn**.\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "e237edff-9219-4e06-cb92-e7a5d0719f14",
        "id": "AMRFPnpbqM2W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 install -U imbalanced-learn scikit-multilearn"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: imbalanced-learn in /usr/local/lib/python3.6/dist-packages (0.4.3)\n",
            "Requirement already up-to-date: scikit-multilearn in /usr/local/lib/python3.6/dist-packages (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.14.6)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.20 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (0.20.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "8vIcwR6xqM2Z",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from skmultilearn.problem_transform import LabelPowerset\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "def oversample(train_x, train_y):\n",
        "  lp = LabelPowerset()\n",
        "  ros = RandomOverSampler(random_state=42)\n",
        "\n",
        "  # Applies the above stated multi-label (ML) to multi-class (MC) transformation.\n",
        "  yt = lp.transform(train_y)\n",
        "  \n",
        "  x_resampled, y_resampled = ros.fit_sample(train_x_token, yt)\n",
        "\n",
        "  # Inverts the ML-MC transformation to recreate the ML set\n",
        "  y_resampled = lp.inverse_transform(y_resampled)\n",
        "  y_resampled = np.asarray([i.toarray()[0] for i in y_resampled])\n",
        "  \n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  (ax_test, ax_train) = fig.subplots(ncols=2, nrows=1)\n",
        "  g1 = sns.barplot(x=train_y.sum(axis=0), y=CATEGORIES, ax=ax_test)\n",
        "  g2 = sns.barplot(x=y_resampled.sum(axis=0), y=CATEGORIES, ax=ax_train)\n",
        "  g1.set_title(\"class distribution before resampling\")\n",
        "  g2.set_title(\"class distribution in training set after resampling\")\n",
        "  \n",
        "  return x_resampled, y_resampled"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "aTQ39hlAqM2d"
      },
      "cell_type": "markdown",
      "source": [
        "# CNN Input\n",
        "\n",
        "Here we take a maximum length of file by obtaining the accumulative density distribution of the training examples. This way we can see how many examples fall under certain threshold. Which will be fixed to 80% of the total examples. This length is 5000 words roughly."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "d77d0f85-e379-49c8-d94e-434e3241fa93",
        "id": "K6yAQwqgqM2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "cell_type": "code",
      "source": [
        "cropped_date_text = [sentence[DATE_LENGTH:] for sentence in train_x]\n",
        "lenghts = [len(sentence[DATE_LENGTH:].split(\" \")) for sentence in cropped_date_text]\n",
        "plt.hist(lenghts, cumulative=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 21.,  61., 112., 159., 186., 195., 197., 199., 201., 202.]),\n",
              " array([ 905. , 1595.5, 2286. , 2976.5, 3667. , 4357.5, 5048. , 5738.5,\n",
              "        6429. , 7119.5, 7810. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeYAAAFKCAYAAADITfxaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMwAABiHMAAAYhDADAGCQ/wNpix5KIm+oDQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f06f4ff20f0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "bNyihoeLqM2h",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Thus, we initialize the maximum word length as\n",
        "max_length = 5000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "fsqp7ukuqM2l",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_x_token, tokenizer, max_length = tokenize_clean_text(train_x, max_length=max_length)\n",
        "\n",
        "if any([p[\"oversampling\"] for p in network_parameters]):\n",
        "  train_x_oversampled, train_y_oversampled = oversample(train_x_token, train_y)\n",
        "  \n",
        "test_x_token, _, _ = tokenize_clean_text(test_x, tokenizer, max_length)\n",
        "assert len(train_x_token) == len(train_x)\n",
        "assert len(test_x_token) == len(test_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "t_XzzFpUqM2o"
      },
      "cell_type": "markdown",
      "source": [
        "# **TensorBoard**\n",
        "TensorBoard is a great tool for DL visualization. It shows the evolution of metrics during the training phase, as well as the weights, distributions, and even the graph of the neural net. \n",
        "\n",
        "We will be using tensorboardcolab in order to run a \n",
        "TensorBoard instance. This will initialize a ngrok machine and launch TensorBoard for us to see. \n",
        "\n",
        "TensorBoard will be accesible by the url "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "38d3e9da-0890-4188-f6ef-54ee28d37dfc",
        "id": "Sbcq5gOMqM2p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# We install tensorboard colab in case we don't have it already.\n",
        "!pip install tensorboardcolab"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.22)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "021c6300-fb3e-42a6-96d7-e7541f8acd33",
        "id": "79ivurQUqM2t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorboardcolab as tb\n",
        "\n",
        "tbc=tb.TensorBoardColab()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "https://fb20e477.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Gyam03X6qM2x"
      },
      "cell_type": "markdown",
      "source": [
        "# Load the embeddings\n",
        "\n",
        "In this step, we load the word embeddings from the wikipedia, pubmed and PMC. Then we filter them adapting to the words we have in our dataset. This is, if the word appears in the pubmed we take its weights, which are set to 0 otherwise."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "6efdf5a0-ad4e-41eb-c955-953143766598",
        "id": "SJO1m5MwqM2y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "cell_type": "code",
      "source": [
        "# seemingly gensim is not installed in google colab\n",
        "!pip install gensim"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.7.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.6)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.1.0)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (0.98)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.9.75)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.11.29)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.75 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.12.75)\n",
            "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.1.13)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.75->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.75->boto3->smart-open>=1.2.1->gensim) (0.14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zJsmyAUOqM20",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "\n",
        "PATH_W2V = \"drive/My Drive/Colab Notebooks/CohortSelection/DL/word2vect/wikipedia-pubmed-and-PMC-w2v.bin\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "81mK3tCEqM22",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_W2V_model(path):\n",
        "    model = KeyedVectors.load_word2vec_format(path, binary=True)\n",
        "    print(\"Loaded W2V model\")\n",
        "    return model\n",
        "  \n",
        "def generate_embedding_weigths(word_index, max_words, model):\n",
        "  embedding_matrix = np.zeros((max_words, model.vector_size), dtype=np.float32)\n",
        "  for word, i in word_index.items():\n",
        "    if i >= max_words:\n",
        "        break\n",
        "    if word in model:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = model[word]\n",
        "  return embedding_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6qPp111eqM26",
        "outputId": "62ecff9d-d731-46fe-bbdf-4f10f73660e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "if any([p[\"load_embeddings\"] for p in network_parameters]):\n",
        "  # load the model\n",
        "  if not 'model' in locals():\n",
        "    model = load_W2V_model(PATH_W2V)\n",
        "  # Generate the weights matrix\n",
        "  embedding_matrix = generate_embedding_weigths(tokenizer.word_index, MAX_WORDS, model)\n",
        "  # Set the embeddings size to the size of the embedding vector\n",
        "  for p in network_parameters:\n",
        "    if p[\"load_embeddings\"]:\n",
        "      p[\"embeddings_size\"] = model.vector_size"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded W2V model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dwBfSAEepvSs",
        "colab_type": "code",
        "outputId": "5ee1b65c-e1c2-4158-831a-0ce6fc458407",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "cell_type": "code",
      "source": [
        "network_parameters"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'batch_size': 32,\n",
              "  'conv_filter': [10],\n",
              "  'conv_size': [128],\n",
              "  'dropout': 0.1,\n",
              "  'embeddings_size': 200,\n",
              "  'fnn_size': [64, 13],\n",
              "  'load_embeddings': True,\n",
              "  'num_classes': None,\n",
              "  'oversampling': False},\n",
              " {'batch_size': 32,\n",
              "  'conv_filter': [10],\n",
              "  'conv_size': [128],\n",
              "  'dropout': 0.1,\n",
              "  'embeddings_size': 200,\n",
              "  'fnn_size': [64, 13],\n",
              "  'load_embeddings': False,\n",
              "  'num_classes': None,\n",
              "  'oversampling': False}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "REWEkTebqM3C"
      },
      "cell_type": "markdown",
      "source": [
        "#**Create a keras Embedding model**\n",
        "\n",
        "In this section we will create a Keras CNN model, compile, and train it.\n",
        "\n",
        "In this model we can decide to generate the different embeddings for the words by training the Embedding Keras layer, or simply use a pre-trained embeddings as the wikipedia ones for example.\n",
        "\n",
        "Some information about the architecture of the net is shown bellow. "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "MUBwiIvyqM3C",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Activation, Embedding, Flatten, GlobalMaxPool1D\n",
        "from keras.layers import MaxPooling1D, Dropout, Conv1D, Input\n",
        "from keras.layers.merge import Concatenate, add\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils.vis_utils import plot_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NMK1z7KLulK3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "JF3OUwmJqM3F",
        "outputId": "5464d64c-c4a7-45ea-cc49-400ae3a7c8d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1040
        }
      },
      "cell_type": "code",
      "source": [
        "# Generate the sequential baseline model\n",
        "model_list = []\n",
        "print(len(network_parameters))\n",
        "for param in network_parameters:\n",
        "  # oversampling, load_embeddings, num_classes, embeddings_size, conv_size, conv_filter, dropout, fnn_size, batch_size\n",
        "  model_input = Input(shape=(max_length,))\n",
        "  # Add the embeddings\n",
        "  if param[\"load_embeddings\"]:\n",
        "    z = Embedding(MAX_WORDS, param[\"embeddings_size\"], input_length=max_length, weights=[embedding_matrix], trainable=False)(model_input)\n",
        "  else:\n",
        "    z = Embedding(MAX_WORDS, param[\"embeddings_size\"], input_length=max_length)(model_input)\n",
        "    \n",
        "  z = Dropout(param[\"dropout\"])(z)\n",
        "            \n",
        "  # Add the cnn\n",
        "  conv_blocks = []\n",
        "  for filter_size in param[\"conv_filter\"]:\n",
        "    conv = None\n",
        "    for i, cnn_layer in enumerate(param[\"conv_size\"]):\n",
        "      conv = Conv1D(cnn_layer, filter_size, padding='valid', activation='relu', strides=1)(z if conv is None else conv)\n",
        "      if (i + 1) % 2 == 0:\n",
        "        conv = MaxPooling1D(pool_size=filter_size)(conv)        \n",
        "    \n",
        "    conv_block = Flatten()(conv)\n",
        "    conv_blocks.append(conv_block)         \n",
        "   \n",
        "  z = Concatenate()(conv_blocks) if len(conv_blocks) > 1 else conv_blocks[0]\n",
        "            \n",
        "  # Add the fnn\n",
        "  fnn = None\n",
        "  for fnn_layer in param[\"fnn_size\"]:\n",
        "    if fnn_layer is None:\n",
        "      break\n",
        "    fnn = Dense(fnn_layer)(z if fnn is None else fnn)\n",
        "    fnn = Dropout(param[\"dropout\"])(fnn)\n",
        "  \n",
        "  if param[\"num_classes\"] is None:\n",
        "    param[\"num_classes\"] = len(train_y[0])\n",
        "    \n",
        "  fnn = Dense(param[\"num_classes\"])(z if fnn is None else fnn)\n",
        "  model_output = Activation('sigmoid')(fnn)\n",
        "\n",
        "  net_model = Model(model_input, model_output)\n",
        "  # Compile the model\n",
        "  net_model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\",\n",
        "                    metrics=[\"acc\"])\n",
        "\n",
        "  # Print a summary of it.\n",
        "  net_model.summary()\n",
        "  plot_model(net_model, to_file=SST_HOME+\"DL/models/\"+'model_{}.png'.format(len(model_list)))\n",
        "  model_list.append(net_model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 5000)              0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 5000, 200)         1000000   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 5000, 200)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 4991, 128)         256128    \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 638848)            0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                40886336  \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 13)                845       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 13)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 13)                182       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 13)                0         \n",
            "=================================================================\n",
            "Total params: 42,143,491\n",
            "Trainable params: 41,143,491\n",
            "Non-trainable params: 1,000,000\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 5000)              0         \n",
            "_________________________________________________________________\n",
            "embedding_2 (Embedding)      (None, 5000, 200)         1000000   \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 5000, 200)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 4991, 128)         256128    \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 638848)            0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                40886336  \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 13)                845       \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 13)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 13)                182       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 13)                0         \n",
            "=================================================================\n",
            "Total params: 42,143,491\n",
            "Trainable params: 42,143,491\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mE62gMQ0e4WG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_model(net_model, to_file=SST_HOME+\"DL/models/\"+'model_{}.png'.format(len(model_list)))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "U6YqAZ5iqM3I",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from keras.callbacks import TensorBoard\n",
        "import tensorflow as tf\n",
        "\n",
        "class TensorBoardColabCallback(TensorBoard):\n",
        "    def __init__(self, tbc=None, write_graph=True, name=None, **kwargs):\n",
        "        # Make the original `TensorBoard` log to a subdirectory 'training'\n",
        "\n",
        "        if tbc is None:\n",
        "            return\n",
        "\n",
        "        log_dir = tbc.get_graph_path()\n",
        "\n",
        "        training_log_dir = os.path.join(log_dir, 'training_{}'.format(name))\n",
        "        super(TensorBoardColabCallback, self).__init__(training_log_dir, **kwargs)\n",
        "\n",
        "        # Log the validation metrics to a separate subdirectory\n",
        "        self.val_log_dir = os.path.join(log_dir, 'validation_{}'.format(name))\n",
        "\n",
        "    def set_model(self, model):\n",
        "        # Setup writer for validation metrics\n",
        "        self.val_writer = tf.summary.FileWriter(self.val_log_dir)\n",
        "        super(TensorBoardColabCallback, self).set_model(model)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Pop the validation logs and handle them separately with\n",
        "        # `self.val_writer`. Also rename the keys so that they can\n",
        "        # be plotted on the same figure with the training metrics\n",
        "        logs = logs or {}\n",
        "        val_logs = {k.replace('val_', ''): v for k, v in logs.items() if k.startswith('val_')}\n",
        "\n",
        "        for name, value in val_logs.items():\n",
        "            # print('val_logs:',epoch, name, value)\n",
        "            summary = tf.Summary()\n",
        "            summary_value = summary.value.add()\n",
        "            summary_value.simple_value = value.item()\n",
        "            summary_value.tag = name\n",
        "            self.val_writer.add_summary(summary, epoch)\n",
        "        self.val_writer.flush()\n",
        "\n",
        "        # Pass the remaining logs to `TensorBoard.on_epoch_end`\n",
        "        logs = {k: v for k, v in logs.items() if not k.startswith('val_')}\n",
        "        super(TensorBoardColabCallback, self).on_epoch_end(epoch, logs)\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        super(TensorBoardColabCallback, self).on_train_end(logs)\n",
        "        self.val_writer.close()\n",
        "\n",
        "tb.TensorBoardColabCallback = TensorBoardColabCallback"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "BcYNuc7BqM3J",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def define_callbacks(name):\n",
        "  # Define the callbacks\n",
        "  tbc_callback = tb.TensorBoardColabCallback(tbc, name=name)\n",
        "   \n",
        "  callbacks = [\n",
        "      ReduceLROnPlateau(),\n",
        "      # EarlyStopping(patience=4),\n",
        "      tbc_callback\n",
        "  ]\n",
        "  return callbacks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ySeqkndhqM3L",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create an array of names\n",
        "network_names = []\n",
        "for p in network_parameters:\n",
        "  name = \"oversampling_{}_load_embeddings_t_{}_num_classes_{}_embeddings_size_{}_conv_size_{}_conv_filter_{}_dropout_{}_fnn_size_{}_batch_size_{}\".format(\n",
        "      p[\"oversampling\"], p[\"load_embeddings\"], p[\"num_classes\"], p[\"embeddings_size\"],\n",
        "      p[\"conv_size\"], p[\"conv_filter\"], p[\"dropout\"], p[\"fnn_size\"], p[\"batch_size\"])\n",
        "  name = name.replace(\" \", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"-\")\n",
        "  network_names.append(name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cNX6et1k3k4P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## The models are trained"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ocpei7QUqM3O",
        "outputId": "86d6a2f7-8cfd-43a2-b9f3-c642a73a46ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2305
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "for i, net_model in enumerate(model_list):\n",
        "  # Set a name for the model based on the tweaked parameters\n",
        "  p = network_parameters[i]\n",
        "  name = network_names[i]\n",
        "  model_path = SST_HOME+\"DL/models/\" + name\n",
        "\n",
        "  # If the model exists, don't compute it again.\n",
        "  if os.path.isfile(model_path):\n",
        "    continue\n",
        "    \n",
        "  print(\"\\n\\n********************************************\\n\")    \n",
        "  print(network_names[i])\n",
        "  callbacks = define_callbacks(network_names[i])\n",
        "  # Fit the model and extract its data\n",
        "  if network_parameters[i][\"oversampling\"]:\n",
        "    history = net_model.fit(train_x_oversampled, train_y_oversampled, epochs=30, batch_size=network_parameters[i][\"batch_size\"], \n",
        "                            class_weight=class_weight, callbacks=callbacks,\n",
        "                            validation_split=0.25)\n",
        "  else:\n",
        "    history = net_model.fit(train_x_token, train_y, epochs=30, batch_size=network_parameters[i][\"batch_size\"], \n",
        "                            class_weight=class_weight, callbacks=callbacks,\n",
        "                            validation_split=0.25)\n",
        "      \n",
        "  # And save the model\n",
        "  net_model.save(model_path)\n",
        "  \n",
        "# To free memory from the gpu\n",
        "from keras import backend as K\n",
        "K.clear_session()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "********************************************\n",
            "\n",
            "oversampling_False_load_embeddings_t_True_num_classes_13_embeddings_size_200_conv_size_128_conv_filter_10_dropout_0.1_fnn_size_64-13_batch_size_32\n",
            "Train on 151 samples, validate on 51 samples\n",
            "Epoch 1/30\n",
            "151/151 [==============================] - 4s 28ms/step - loss: 2.0990 - acc: 0.7152 - val_loss: 0.8674 - val_acc: 0.7451\n",
            "Epoch 2/30\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 0.6248 - acc: 0.7590 - val_loss: 0.6279 - val_acc: 0.7345\n",
            "Epoch 3/30\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 0.6098 - acc: 0.7911 - val_loss: 0.6611 - val_acc: 0.7451\n",
            "Epoch 4/30\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 0.6272 - acc: 0.8176 - val_loss: 0.6536 - val_acc: 0.7391\n",
            "Epoch 5/30\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 0.5974 - acc: 0.8502 - val_loss: 0.6277 - val_acc: 0.7421\n",
            "Epoch 6/30\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 0.5225 - acc: 0.8604 - val_loss: 0.5445 - val_acc: 0.7526\n",
            "Epoch 7/30\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 0.4148 - acc: 0.8380 - val_loss: 0.4816 - val_acc: 0.7451\n",
            "Epoch 8/30\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 0.3478 - acc: 0.8579 - val_loss: 0.4922 - val_acc: 0.7557\n",
            "Epoch 9/30\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 0.2843 - acc: 0.8976 - val_loss: 0.4947 - val_acc: 0.7557\n",
            "Epoch 10/30\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 0.2305 - acc: 0.9129 - val_loss: 0.5198 - val_acc: 0.7602\n",
            "Epoch 11/30\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 0.1856 - acc: 0.9328 - val_loss: 0.5568 - val_acc: 0.7632\n",
            "Epoch 12/30\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 0.1780 - acc: 0.9353 - val_loss: 0.6165 - val_acc: 0.7738\n",
            "Epoch 13/30\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 0.1618 - acc: 0.9424 - val_loss: 0.5996 - val_acc: 0.7828\n",
            "Epoch 14/30\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 0.1225 - acc: 0.9582 - val_loss: 0.6081 - val_acc: 0.7768\n",
            "Epoch 15/30\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 0.1417 - acc: 0.9536 - val_loss: 0.6414 - val_acc: 0.7768\n",
            "Epoch 16/30\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 0.1303 - acc: 0.9562 - val_loss: 0.5988 - val_acc: 0.7722\n",
            "Epoch 17/30\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 0.1244 - acc: 0.9587 - val_loss: 0.5960 - val_acc: 0.7677\n",
            "Epoch 18/30\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 0.0972 - acc: 0.9699 - val_loss: 0.5990 - val_acc: 0.7677\n",
            "Epoch 19/30\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 0.1115 - acc: 0.9603 - val_loss: 0.6018 - val_acc: 0.7707\n",
            "Epoch 20/30\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 0.0909 - acc: 0.9694 - val_loss: 0.6061 - val_acc: 0.7707\n",
            "Epoch 21/30\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 0.1114 - acc: 0.9592 - val_loss: 0.6124 - val_acc: 0.7692\n",
            "Epoch 22/30\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 0.1015 - acc: 0.9603 - val_loss: 0.6176 - val_acc: 0.7677\n",
            "Epoch 23/30\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 0.0706 - acc: 0.9817 - val_loss: 0.6256 - val_acc: 0.7647\n",
            "Epoch 24/30\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 0.0989 - acc: 0.9684 - val_loss: 0.6321 - val_acc: 0.7677\n",
            "Epoch 25/30\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 0.1128 - acc: 0.9582 - val_loss: 0.6352 - val_acc: 0.7677\n",
            "Epoch 26/30\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 0.0945 - acc: 0.9725 - val_loss: 0.6355 - val_acc: 0.7662\n",
            "Epoch 27/30\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 0.1033 - acc: 0.9618 - val_loss: 0.6360 - val_acc: 0.7647\n",
            "Epoch 28/30\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 0.0969 - acc: 0.9648 - val_loss: 0.6360 - val_acc: 0.7647\n",
            "Epoch 29/30\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 0.1081 - acc: 0.9633 - val_loss: 0.6354 - val_acc: 0.7662\n",
            "Epoch 30/30\n",
            "151/151 [==============================] - 1s 6ms/step - loss: 0.0834 - acc: 0.9745 - val_loss: 0.6351 - val_acc: 0.7662\n",
            "\n",
            "\n",
            "********************************************\n",
            "\n",
            "oversampling_False_load_embeddings_t_False_num_classes_13_embeddings_size_200_conv_size_128_conv_filter_10_dropout_0.1_fnn_size_64-13_batch_size_32\n",
            "Train on 151 samples, validate on 51 samples\n",
            "Epoch 1/30\n",
            "151/151 [==============================] - 2s 12ms/step - loss: 2.4245 - acc: 0.6327 - val_loss: 0.9669 - val_acc: 0.7315\n",
            "Epoch 2/30\n",
            "151/151 [==============================] - 1s 7ms/step - loss: 0.7512 - acc: 0.6852 - val_loss: 0.6366 - val_acc: 0.6290\n",
            "Epoch 3/30\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 0.6385 - acc: 0.7173 - val_loss: 0.6790 - val_acc: 0.7029\n",
            "Epoch 4/30\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 0.6688 - acc: 0.7631 - val_loss: 0.6779 - val_acc: 0.7044\n",
            "Epoch 5/30\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 0.6616 - acc: 0.7621 - val_loss: 0.6661 - val_acc: 0.6576\n",
            "Epoch 6/30\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 0.6273 - acc: 0.7366 - val_loss: 0.6125 - val_acc: 0.6335\n",
            "Epoch 7/30\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 0.5394 - acc: 0.7152 - val_loss: 0.5392 - val_acc: 0.7210\n",
            "Epoch 8/30\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 0.4597 - acc: 0.7820 - val_loss: 0.5371 - val_acc: 0.7436\n",
            "Epoch 9/30\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 0.4046 - acc: 0.8344 - val_loss: 0.5108 - val_acc: 0.7768\n",
            "Epoch 10/30\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 0.3677 - acc: 0.8487 - val_loss: 0.5030 - val_acc: 0.7722\n",
            "Epoch 11/30\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 0.2992 - acc: 0.8828 - val_loss: 0.5154 - val_acc: 0.7813\n",
            "Epoch 12/30\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 0.2722 - acc: 0.8940 - val_loss: 0.4945 - val_acc: 0.7858\n",
            "Epoch 13/30\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 0.2322 - acc: 0.9093 - val_loss: 0.4998 - val_acc: 0.7753\n",
            "Epoch 14/30\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 0.2180 - acc: 0.9129 - val_loss: 0.5179 - val_acc: 0.7843\n",
            "Epoch 15/30\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 0.1852 - acc: 0.9302 - val_loss: 0.5602 - val_acc: 0.7843\n",
            "Epoch 16/30\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 0.1991 - acc: 0.9246 - val_loss: 0.5546 - val_acc: 0.7783\n",
            "Epoch 17/30\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 0.1759 - acc: 0.9404 - val_loss: 0.5275 - val_acc: 0.7843\n",
            "Epoch 18/30\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 0.1829 - acc: 0.9226 - val_loss: 0.5306 - val_acc: 0.7813\n",
            "Epoch 19/30\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 0.1521 - acc: 0.9475 - val_loss: 0.5924 - val_acc: 0.7843\n",
            "Epoch 20/30\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 0.1453 - acc: 0.9491 - val_loss: 0.5604 - val_acc: 0.7828\n",
            "Epoch 21/30\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 0.1370 - acc: 0.9501 - val_loss: 0.5327 - val_acc: 0.7934\n",
            "Epoch 22/30\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 0.1151 - acc: 0.9557 - val_loss: 0.6092 - val_acc: 0.7798\n",
            "Epoch 23/30\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 0.1376 - acc: 0.9409 - val_loss: 0.5933 - val_acc: 0.7798\n",
            "Epoch 24/30\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 0.1396 - acc: 0.9496 - val_loss: 0.5772 - val_acc: 0.7798\n",
            "Epoch 25/30\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 0.1274 - acc: 0.9542 - val_loss: 0.5694 - val_acc: 0.7873\n",
            "Epoch 26/30\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 0.1031 - acc: 0.9603 - val_loss: 0.5692 - val_acc: 0.7903\n",
            "Epoch 27/30\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 0.1132 - acc: 0.9531 - val_loss: 0.5702 - val_acc: 0.7873\n",
            "Epoch 28/30\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 0.1383 - acc: 0.9440 - val_loss: 0.5661 - val_acc: 0.7843\n",
            "Epoch 29/30\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 0.1257 - acc: 0.9562 - val_loss: 0.5618 - val_acc: 0.7798\n",
            "Epoch 30/30\n",
            "151/151 [==============================] - 1s 8ms/step - loss: 0.1132 - acc: 0.9582 - val_loss: 0.5579 - val_acc: 0.7798\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2MW44vf23uRv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## The models are loaded\n"
      ]
    },
    {
      "metadata": {
        "id": "Yn5DDecUb_vW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "  from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "JetxGmrtqM3W",
        "outputId": "9e3f39d8-7304-4e6b-d4eb-5c900565e322",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 988
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "predictions_list = []\n",
        "for i, net_model in enumerate(model_list):\n",
        "  print(\"\\n\\n********************************************\\n\")\n",
        "  print(network_names[i])\n",
        "  model_path = SST_HOME+\"DL/models/\" + network_names[i]\n",
        "  try:\n",
        "    net_model = load_model(model_path)\n",
        "  except ValueError:\n",
        "    print(\"The model {} was not loaded correctly\".format(name))\n",
        "    continue\n",
        "    \n",
        "  predictions = net_model.predict(test_x_token)\n",
        "  predictions = np.array([[0 if value < 0.5 else 1 for value in prediction] for prediction in predictions])\n",
        "  predictions_list.append(predictions)\n",
        "  # measuring performance on test set\n",
        "  cr=classification_report(test_y, predictions, target_names=CATEGORIES.values)\n",
        "  print(cr)\n",
        "\n",
        "  # Release memory\n",
        "  K.clear_session()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "********************************************\n",
            "\n",
            "oversampling_False_load_embeddings_t_True_num_classes_13_embeddings_size_200_conv_size_128_conv_filter_10_dropout_0.1_fnn_size_64-13_batch_size_32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "     ASP-FOR-MI       0.77      1.00      0.87        23\n",
            "      ABDOMINAL       0.50      0.09      0.15        11\n",
            "  DIETSUPP-2MOS       0.47      0.44      0.45        16\n",
            "   ADVANCED-CAD       0.50      0.88      0.64        16\n",
            "       KETO-1YR       0.00      0.00      0.00         0\n",
            " MAJOR-DIABETES       0.58      0.69      0.63        16\n",
            "          HBA1C       0.50      0.10      0.17        10\n",
            "MAKES-DECISIONS       0.93      1.00      0.97        28\n",
            "  ALCOHOL-ABUSE       0.00      0.00      0.00         1\n",
            "        ENGLISH       0.90      1.00      0.95        27\n",
            "     DRUG-ABUSE       0.00      0.00      0.00         2\n",
            "     CREATININE       0.33      0.22      0.27         9\n",
            "        MI-6MOS       0.00      0.00      0.00         2\n",
            "\n",
            "      micro avg       0.70      0.71      0.71       161\n",
            "      macro avg       0.42      0.42      0.39       161\n",
            "   weighted avg       0.66      0.71      0.66       161\n",
            "    samples avg       0.72      0.72      0.71       161\n",
            "\n",
            "\n",
            "\n",
            "********************************************\n",
            "\n",
            "oversampling_False_load_embeddings_t_False_num_classes_13_embeddings_size_200_conv_size_128_conv_filter_10_dropout_0.1_fnn_size_64-13_batch_size_32\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "     ASP-FOR-MI       0.77      1.00      0.87        23\n",
            "      ABDOMINAL       0.50      0.09      0.15        11\n",
            "  DIETSUPP-2MOS       0.50      0.44      0.47        16\n",
            "   ADVANCED-CAD       0.52      0.94      0.67        16\n",
            "       KETO-1YR       0.00      0.00      0.00         0\n",
            " MAJOR-DIABETES       0.53      1.00      0.70        16\n",
            "          HBA1C       0.00      0.00      0.00        10\n",
            "MAKES-DECISIONS       0.93      1.00      0.97        28\n",
            "  ALCOHOL-ABUSE       0.00      0.00      0.00         1\n",
            "        ENGLISH       0.90      1.00      0.95        27\n",
            "     DRUG-ABUSE       0.00      0.00      0.00         2\n",
            "     CREATININE       0.33      0.11      0.17         9\n",
            "        MI-6MOS       0.00      0.00      0.00         2\n",
            "\n",
            "      micro avg       0.70      0.73      0.72       161\n",
            "      macro avg       0.38      0.43      0.38       161\n",
            "   weighted avg       0.63      0.73      0.65       161\n",
            "    samples avg       0.70      0.74      0.71       161\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XmgYwJUqG5Tv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "1cCd5xkYqM3d"
      },
      "cell_type": "markdown",
      "source": [
        "#**Generating output in XML format**\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UPDeSPwfqM3e",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree\n",
        "import os\n",
        "NOT='not met'\n",
        "MET='met'\n",
        "\n",
        "#gets a idFile, a dictionary with the predictions (category, label) and the name of the classifier used.\n",
        "def outputToXML(idFile, dictPred, classifier):\n",
        "    \n",
        "    path=SST_HOME+'data/test/xml/'+idFile+'.xml'\n",
        "    output_dir = SST_HOME+'data/output/'+classifier\n",
        "    \n",
        "    output = output_dir+'/'+idFile+'.xml'\n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "      print(\"\\n\\nmaking dir\")\n",
        "      s = os.makedirs(output_dir)\n",
        "      print(output_dir)\n",
        "      print(s)      \n",
        "   \n",
        "    et = xml.etree.ElementTree.parse(path)\n",
        "\n",
        "    new_tag = xml.etree.ElementTree.SubElement(et.getroot(), 'TAGS')\n",
        "    \n",
        "    for cat in dictPred.keys():\n",
        "        element = xml.etree.ElementTree.SubElement(new_tag, cat)    \n",
        "        if dictPred[cat]==0:\n",
        "            element.attrib['met'] = NOT \n",
        "        else:\n",
        "            element.attrib['met'] = MET\n",
        "\n",
        "    et.write(output)\n",
        "\n",
        "#function for creating a dictionary with the categories with values 0 or 1\n",
        "def iniDictPred(labels, categories):\n",
        "    \n",
        "    if len(labels)!=len(categories):\n",
        "        print('Warning!!!')\n",
        "        return None\n",
        "    \n",
        "    dictPred={}\n",
        "    i=0\n",
        "    \n",
        "    for x in categories:\n",
        "        dictPred[x]=labels[i]\n",
        "        i=i+1\n",
        "    return dictPred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3Ua3D6lQqM3f",
        "outputId": "3e3eaee0-d5dd-413d-ff50-728f3201f859",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "cell_type": "code",
      "source": [
        "#creates the output xml files per training\n",
        "for i, predictions in enumerate(predictions_list):\n",
        "  dictionary = zip(IDFILES, predictions)\n",
        "  for obj in dictionary:\n",
        "      idFile=str(obj[0][0])\n",
        "      labels=obj[1] #gets their predictions for this file\n",
        "      dictPred=iniDictPred(labels, CATEGORIES) #creates a dictionary to join categories and labels 0,1\n",
        "      outputToXML(idFile,dictPred,\"CNN/{}\".format(network_names[i]))\n",
        "\n",
        "  print('output xml files were generated!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "making dir\n",
            "drive/My Drive/Colab Notebooks/CohortSelection/data/output/CNN/oversampling_False_load_embeddings_t_True_num_classes_13_embeddings_size_200_conv_size_128_conv_filter_10_dropout_0.1_fnn_size_64-13_batch_size_32\n",
            "None\n",
            "output xml files were generated!\n",
            "\n",
            "\n",
            "making dir\n",
            "drive/My Drive/Colab Notebooks/CohortSelection/data/output/CNN/oversampling_False_load_embeddings_t_False_num_classes_13_embeddings_size_200_conv_size_128_conv_filter_10_dropout_0.1_fnn_size_64-13_batch_size_32\n",
            "None\n",
            "output xml files were generated!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "IiigZnfNqM3m",
        "outputId": "ee390e69-ee6e-47e4-ca20-b3aa31939342",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "# Writes the output in a file for each training.\n",
        "for i, name in enumerate(network_names):\n",
        "  print(name) \n",
        "  path = \"data/output/CNN/\"\n",
        "  n = path + \"{}\".format(name)\n",
        "  os.system('cd \"{}\" && echo \"{}\" {} {}results.txt'.format(SST_HOME, name, \">\" if i == 0 else \">>\", path))\n",
        "  os.system('cd \"{}\" && python3 track1_eval.py data/test/gold {} >> {}results.txt'.format(SST_HOME, n, path))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "oversampling_False_load_embeddings_t_True_num_classes_13_embeddings_size_200_conv_size_128_conv_filter_10_dropout_0.1_fnn_size_64-13_batch_size_32\n",
            "oversampling_False_load_embeddings_t_False_num_classes_13_embeddings_size_200_conv_size_128_conv_filter_10_dropout_0.1_fnn_size_64-13_batch_size_32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dP0jddTMAF22",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}