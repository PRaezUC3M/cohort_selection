{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN-base.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PRaezUC3M/cohort_selection/blob/master/CNN_base.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "VUhjUt2_2taj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Mount the drive folder**"
      ]
    },
    {
      "metadata": {
        "id": "XsZ86gUk2ne4",
        "colab_type": "code",
        "outputId": "a630e3a6-74e8-4572-d990-436f00f75332",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vluB44afpEHL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Configurartion of the experiments**\n",
        "The different possible experiments have been automated. It is inspired in grid-search, and the parameters must be expressed in array-like style. You can find an example below.\n",
        "\n",
        "Every possible example will be generated from the combination of the different parameters given."
      ]
    },
    {
      "metadata": {
        "id": "GkCE2veNaxhq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "AdJIJMn1pbCa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Baseline Model\n",
        "oversampling = [False]\n",
        "load_embeddings = [False] # This defines if the embeddings are loaded from the wikipedia dataset\n",
        "num_classes = [None] # Auto\n",
        "embeddings_size = [200, 300]\n",
        "conv_size = [[128]] #, [256], [256, 128]]\n",
        "conv_filter = [[3, 4, 5]]\n",
        "dropout = [0.1]\n",
        "fnn_size = [[64, 13]]\n",
        "\n",
        "indexes = [\"oversampling\", \"load_embeddings\", \"num_classes\", \"embeddings_size\", \"conv_size\", \"conv_filter\", \"dropout\", \"fnn_size\"]\n",
        "param   = [oversampling, load_embeddings, num_classes, embeddings_size, conv_size, conv_filter, dropout, fnn_size]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b65TBRSg3wep",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "def combine_params(param, indexes):\n",
        "  combinations = list(itertools.product(*param))\n",
        "  param_combinations = [{k:v for k, v in zip(indexes, combination)}  for combination in combinations]\n",
        "  for p in param_combinations:\n",
        "    # The embeddings size must adapt to the embeddings loaded.\n",
        "    if p[\"load_embeddings\"]:\n",
        "      p[\"embeddings_size\"] = None\n",
        "  return param_combinations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N-nFuYPyy8eW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "network_parameters = combine_params(param, indexes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HA9j8Odl20Qj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Load the train and test csv files**\n",
        "This functions load the data and generate the different datasets from the given csv files. "
      ]
    },
    {
      "metadata": {
        "id": "K-Emhq-R2tLE",
        "colab_type": "code",
        "outputId": "4c8363b0-5ced-499e-a99d-11b7423f828f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "SST_HOME='drive/My Drive/Colab Notebooks/CohortSelection/'\n",
        "path_train=SST_HOME+'data/train/train.csv'\n",
        "path_test=SST_HOME+'data/test/test.csv'\n",
        "\n",
        "def load(path):\n",
        "  \n",
        "  df = pd.read_csv(path,header=0, delimiter=\"\\t\", quoting=3)\n",
        "\n",
        "  categories=df.columns[2:]\n",
        "  idFiles = df[['IDFILE']].as_matrix().tolist()\n",
        "\n",
        "  texts = df[['TEXT']].as_matrix()\n",
        "  X = [x[0].strip() for x in texts.tolist()]\n",
        "\n",
        "  #we only keep the columns with the categories.\n",
        "  Y = df.drop(['IDFILE', 'TEXT'], axis=1).as_matrix()\n",
        "\n",
        "\n",
        "  print(path,'dataset loaded')\n",
        "  \n",
        "  return X, Y, categories, idFiles\n",
        "\n",
        "\n",
        "train_x, train_y, CATEGORIES, _ = load(path_train)\n",
        "test_x, test_y, _, IDFILES = load(path_test)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive/My Drive/Colab Notebooks/CohortSelection/data/train/train.csv dataset loaded\n",
            "drive/My Drive/Colab Notebooks/CohortSelection/data/test/test.csv dataset loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mfK0DBRqNVeL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#**Balancing the categories**\n",
        "We can see that there are some categories way more present than others in our dataset. Let's sort them."
      ]
    },
    {
      "metadata": {
        "id": "ABuXlWNYMuow",
        "colab_type": "code",
        "outputId": "28c05491-5c98-45f7-8c64-f698a0aa9218",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        }
      },
      "cell_type": "code",
      "source": [
        "classes = np.add(sum(train_y), sum(test_y))\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(classes)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7feacb9c37f0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAFKCAYAAADMuCxnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7feacba2a080>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "cg3-Y6mkN_v4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we can see the differences in a easier way, we will add weights to the different classes, based on how present they are in the dataset."
      ]
    },
    {
      "metadata": {
        "id": "vSNK4zzBN9S4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "total_cases = sum(classes)\n",
        "class_weight = [1 / (c/total_cases) for c in classes]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ahWzoz_g7JWE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Tokenize the dataset and use the word embeddings**\n",
        "\n",
        "This shows the set of different words ordered by frequency. *tokenizer.word_index*\n",
        "\n",
        "The text is tokenized and cleaned of stop-words as well as punctuation signs. Also the numbers are substituted by a token \"nmbr\"\n",
        "\n",
        "We crop the beggining of the examples because it is the date when they\n",
        "were written down.\n",
        "\n",
        "Finally, and after being tokenized, the different sentences are padded to match the maximum length.\n",
        "\n",
        "max_length == 7813 it is really a huge vector because we have to pad\n",
        "it afterwards, in order to get it into the CNN"
      ]
    },
    {
      "metadata": {
        "id": "IWBYdxobTYQJ",
        "colab_type": "code",
        "outputId": "46c84a8a-f1c1-4a3d-ee5c-bd5a42fee150",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words=stopwords.words('english')\n",
        "# Define maximum word length\n",
        "MAX_WORDS = 5000\n",
        "# Defined from the dataset itself.\n",
        "DATE_LENGTH = 23"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AjwTL9Vkhwle",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# We are using this function to clean the test set\n",
        "def tokenize_clean_text(text, tokenizer=None, max_length=None, \n",
        "                        max_words=MAX_WORDS, date_length=DATE_LENGTH):\n",
        "  \"\"\"\n",
        "  This function is in charge of tokenizing the text it is given. It also cleans\n",
        "  the text from stop-words, punctuation, and gives a special token to numbers.\n",
        "  \n",
        "  :param text: The texts to tokenize in a bidimensional python array.\n",
        "  \n",
        "  :returns: The tokenized and cleaned text in a bidimensional python array.\n",
        "            The tokenizer used to preprocess the text.\n",
        "            The maximum length used for padding.\n",
        "  \"\"\"  \n",
        "  # Consider to stemm or lemmatize the text \n",
        "  \n",
        "  cropped_date_text = [sentence[date_length:] for sentence in text]\n",
        "\n",
        "  if max_length == None:\n",
        "    # We get the maximum token length by splitting by spaces\n",
        "    max_length = max([len(sentence[date_length:].split(\" \")) for sentence in cropped_date_text])\n",
        "    \n",
        "  # We remove the numbers\n",
        "  cropped_date_numbers_text = [\" \".join([word if not word.isdigit() else \"\"\n",
        "                                for word in sentence.split()])\n",
        "                               for sentence in cropped_date_text]\n",
        "  \n",
        "  # Delete stopwords as well as every word less than 3 chars.\n",
        "  cropped_date_numbers_stopw_text = [\" \".join([word if not (word in stop_words or len(word) <= 3) else \"\"\n",
        "                                      for word in sentence.split()])\n",
        "                                     for sentence in cropped_date_numbers_text]\n",
        "  \n",
        "  if tokenizer is None:\n",
        "    tokenizer = Tokenizer(num_words=MAX_WORDS) # They use 5k words too\n",
        "    tokenizer.fit_on_texts(cropped_date_numbers_stopw_text)\n",
        "  # We tokenize the sentences\n",
        "  tokenized_text = tokenizer.texts_to_sequences(cropped_date_numbers_stopw_text)\n",
        "  \n",
        "  # Now we return the padded the sequences.\n",
        "  return pad_sequences(tokenized_text, max_length), tokenizer, max_length\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uaDhdU7pY7Qv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Oversampling**\n",
        "\n",
        "As the dataset is very unbalanced, we must perform over-sampling (which is to increase the minority class(es)). The RandomOverSampler **class** allows us to over-sample minority classes by  picking samples at random with replacement. We need to install the package **imbalanced-learn**.\n"
      ]
    },
    {
      "metadata": {
        "id": "4SRFMvOVZNfa",
        "colab_type": "code",
        "outputId": "23b08102-6eeb-4948-cd25-56a91b356133",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 install -U imbalanced-learn scikit-multilearn"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: imbalanced-learn in /usr/local/lib/python3.6/dist-packages (0.4.3)\n",
            "Requirement already up-to-date: scikit-multilearn in /usr/local/lib/python3.6/dist-packages (0.1.0)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.14.6)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.20 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (0.20.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zcN5bEa4A4Ss",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from skmultilearn.problem_transform import LabelPowerset\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "def oversample(train_x, train_y):\n",
        "  lp = LabelPowerset()\n",
        "  ros = RandomOverSampler(random_state=42)\n",
        "\n",
        "  # Applies the above stated multi-label (ML) to multi-class (MC) transformation.\n",
        "  yt = lp.transform(train_y)\n",
        "  \n",
        "  x_resampled, y_resampled = ros.fit_sample(train_x_token, yt)\n",
        "\n",
        "  # Inverts the ML-MC transformation to recreate the ML set\n",
        "  y_resampled = lp.inverse_transform(y_resampled)\n",
        "  y_resampled = np.asarray([i.toarray()[0] for i in y_resampled])\n",
        "  \n",
        "  fig = plt.figure(figsize=(20,20))\n",
        "  (ax_test, ax_train) = fig.subplots(ncols=2, nrows=1)\n",
        "  g1 = sns.barplot(x=train_y.sum(axis=0), y=CATEGORIES, ax=ax_test)\n",
        "  g2 = sns.barplot(x=y_resampled.sum(axis=0), y=CATEGORIES, ax=ax_train)\n",
        "  g1.set_title(\"class distribution before resampling\")\n",
        "  g2.set_title(\"class distribution in training set after resampling\")\n",
        "  \n",
        "  return x_resampled, y_resampled"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xq9Z-kdItQpX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CNN Input\n",
        "\n",
        "Here we take a maximum length of file by obtaining the accumulative density distribution of the training examples. This way we can see how many examples fall under certain threshold. Which will be fixed to 80% of the total examples. This length is 5000 words roughly."
      ]
    },
    {
      "metadata": {
        "id": "QZX0C6mHsSHg",
        "colab_type": "code",
        "outputId": "dcb809ba-a1c3-4186-aab4-ccbb45fa16d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "cell_type": "code",
      "source": [
        "cropped_date_text = [sentence[DATE_LENGTH:] for sentence in train_x]\n",
        "lenghts = [len(sentence[DATE_LENGTH:].split(\" \")) for sentence in cropped_date_text]\n",
        "plt.hist(lenghts, cumulative=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 21.,  61., 112., 159., 186., 195., 197., 199., 201., 202.]),\n",
              " array([ 905. , 1595.5, 2286. , 2976.5, 3667. , 4357.5, 5048. , 5738.5,\n",
              "        6429. , 7119.5, 7810. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeYAAAFKCAYAAADITfxaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMwAABiHMAAAYhDADAGCQ/wNpix5KIm+oDQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fea83b96160>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "LqkB5-T3vXKO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Thus, we initialize the maximum word length as\n",
        "max_length = 5000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NdRl3K-k0DeN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_x_token, tokenizer, max_length = tokenize_clean_text(train_x, max_length=max_length)\n",
        "\n",
        "if any([p[\"oversampling\"] for p in network_parameters]):\n",
        "  train_x_oversampled, train_y_oversampled = oversample(train_x_token, train_y)\n",
        "  \n",
        "test_x_token, _, _ = tokenize_clean_text(test_x, tokenizer, max_length)\n",
        "assert len(train_x_token) == len(train_x)\n",
        "assert len(test_x_token) == len(test_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c1liHvDdIc7C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **TensorBoard**\n",
        "TensorBoard is a great tool for DL visualization. It shows the evolution of metrics during the training phase, as well as the weights, distributions, and even the graph of the neural net. \n",
        "\n",
        "We will be using tensorboardcolab in order to run a \n",
        "TensorBoard instance. This will initialize a ngrok machine and launch TensorBoard for us to see. \n",
        "\n",
        "TensorBoard will be accesible by the url "
      ]
    },
    {
      "metadata": {
        "id": "aN3qI7-RlOMh",
        "colab_type": "code",
        "outputId": "6be0e912-9d79-4059-acea-88b27a17ec68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# We install tensorboard colab in case we don't have it already.\n",
        "!pip install tensorboardcolab"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.19)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RqJWMm4pH-2f",
        "colab_type": "code",
        "outputId": "598089b3-b76a-48e8-97ee-c77effa3931b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorboardcolab as tb\n",
        "\n",
        "tbc=tb.TensorBoardColab()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "http://a4a6c9cd.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R5-_TIkvYMpD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load the embeddings\n",
        "\n",
        "In this step, we load the word embeddings from the wikipedia, pubmed and PMC. Then we filter them adapting to the words we have in our dataset. This is, if the word appears in the pubmed we take its weights, which are set to 0 otherwise."
      ]
    },
    {
      "metadata": {
        "id": "07o9Lj0gY2lX",
        "colab_type": "code",
        "outputId": "2f2e002b-60a3-474d-e473-3b5768199eed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        }
      },
      "cell_type": "code",
      "source": [
        "# seemingly gensim is not installed in google colab\n",
        "!pip install gensim"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.6)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.1.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.7.1)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (0.98)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.9.57)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.3)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.57 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.12.57)\n",
            "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.1.13)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.10.15)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.57->boto3->smart-open>=1.2.1->gensim) (0.14)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.57->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kQ_9uijiYMcm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "\n",
        "PATH_W2V = \"drive/My Drive/Colab Notebooks/CohortSelection/DL/word2vect/wikipedia-pubmed-and-PMC-w2v.bin\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3nKQd17zXvGZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_W2V_model(path):\n",
        "    model = KeyedVectors.load_word2vec_format(path, binary=True)\n",
        "    print(\"Loaded W2V model\")\n",
        "    return model\n",
        "  \n",
        "def generate_embedding_weigths(word_index, max_words, model):\n",
        "  embedding_matrix = np.zeros((max_words, model.vector_size), dtype=np.float32)\n",
        "  for word, i in word_index.items():\n",
        "    if i >= max_words:\n",
        "        break\n",
        "    if word in model:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = model[word]\n",
        "  return embedding_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oARvVSpb9E8H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if any([p[\"load_embeddings\"] for p in network_parameters]):\n",
        "  # load the model\n",
        "  if not 'model' in locals():\n",
        "    model = load_W2V_model(PATH_W2V)\n",
        "  # Generate the weights matrix\n",
        "  embedding_matrix = generate_embedding_weigths(tokenizer.word_index, MAX_WORDS, model)\n",
        "  # Set the embeddings size to the size of the embedding vector\n",
        "  for p in network_parameters:\n",
        "    if p[\"load_embeddings\"]:\n",
        "      p[\"embeddings_size\"] = model.vector_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o6o3v63SBEoy",
        "colab_type": "code",
        "outputId": "678bb93a-874d-4f6e-a1db-3e6c83da9e98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "[p[\"load_embeddings\"] for p in network_parameters]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[False, False]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "dwBfSAEepvSs",
        "colab_type": "code",
        "outputId": "0a7ae910-cd49-4065-fbfc-6f425fd542d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        }
      },
      "cell_type": "code",
      "source": [
        "network_parameters"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'conv_filter': [3, 4, 5],\n",
              "  'conv_size': [128],\n",
              "  'dropout': 0.1,\n",
              "  'embeddings_size': 200,\n",
              "  'fnn_size': [64, 13],\n",
              "  'load_embeddings': False,\n",
              "  'num_classes': None,\n",
              "  'oversampling': False},\n",
              " {'conv_filter': [3, 4, 5],\n",
              "  'conv_size': [128],\n",
              "  'dropout': 0.1,\n",
              "  'embeddings_size': 300,\n",
              "  'fnn_size': [64, 13],\n",
              "  'load_embeddings': False,\n",
              "  'num_classes': None,\n",
              "  'oversampling': False}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "Xz02TQFG3dNE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#**Create a keras Embedding model**\n",
        "\n",
        "In this section we will create a Keras CNN model, compile, and train it.\n",
        "\n",
        "In this model we can decide to generate the different embeddings for the words by training the Embedding Keras layer, or simply use a pre-trained embeddings as the wikipedia ones for example.\n",
        "\n",
        "Some information about the architecture of the net is shown bellow. "
      ]
    },
    {
      "metadata": {
        "id": "W5FrX4FN3A2B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Activation, Embedding, Flatten, GlobalMaxPool1D\n",
        "from keras.layers import MaxPooling1D, Dropout, Conv1D, Input\n",
        "from keras.layers.merge import Concatenate, add\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WWo65gnF3nfx",
        "colab_type": "code",
        "outputId": "5d7dea00-c3d4-479f-c441-2cb0d03b6f97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1672
        }
      },
      "cell_type": "code",
      "source": [
        "# Generate the sequential baseline model\n",
        "model_list = []\n",
        "print(len(network_parameters))\n",
        "for param in network_parameters:\n",
        "  # oversampling, load_embeddings, num_classes, embeddings_size, conv_size, conv_filter, dropout, fnn_size\n",
        "  model_input = Input(shape=(max_length,))\n",
        "  # Add the embeddings\n",
        "  z = Embedding(MAX_WORDS, param[\"embeddings_size\"], input_length=max_length,  trainable=not param[\"load_embeddings\"])(model_input)\n",
        "  z = Dropout(param[\"dropout\"])(z)\n",
        "            \n",
        "  # Add the cnn\n",
        "  conv_blocks = []\n",
        "  for filter_size in param[\"conv_filter\"]:\n",
        "    conv = None\n",
        "    for cnn_layer in param[\"conv_size\"]:\n",
        "      conv = Conv1D(cnn_layer, filter_size, padding='valid', activation='relu', strides=1)(z if conv is None else conv)\n",
        "      conv = MaxPooling1D(pool_size=2)(conv)\n",
        "    \n",
        "    conv_block = Flatten()(conv)\n",
        "    conv_blocks.append(conv_block)         \n",
        "   \n",
        "  z = Concatenate()(conv_blocks) if len(conv_blocks) > 1 else conv_blocks[0]\n",
        "            \n",
        "  # Add the fnn\n",
        "  fnn = None\n",
        "  for fnn_layer in param[\"fnn_size\"]:\n",
        "    fnn = Dense(fnn_layer)(z if fnn is None else fnn)\n",
        "    fnn = Dropout(param[\"dropout\"])(fnn)\n",
        "\n",
        "  model_output = Activation('sigmoid')(fnn)\n",
        "\n",
        "  net_model = Model(model_input, model_output)\n",
        "  # Compile the model\n",
        "  net_model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", \n",
        "                    metrics=[\"categorical_accuracy\"])\n",
        "\n",
        "  # Print a summary of it.\n",
        "  net_model.summary()\n",
        "  model_list.append(net_model)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 5000)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 5000, 200)    1000000     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 5000, 200)    0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 4998, 128)    76928       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 4997, 128)    102528      dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 4996, 128)    128128      dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, 2499, 128)    0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1D)  (None, 2498, 128)    0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1D)  (None, 2498, 128)    0           conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 319872)       0           max_pooling1d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 319744)       0           max_pooling1d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 319744)       0           max_pooling1d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 959360)       0           flatten_1[0][0]                  \n",
            "                                                                 flatten_2[0][0]                  \n",
            "                                                                 flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 64)           61399104    concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 64)           0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 13)           845         dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 13)           0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 13)           0           dropout_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 62,707,533\n",
            "Trainable params: 62,707,533\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 5000)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 5000, 300)    1500000     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 5000, 300)    0           embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 4998, 128)    115328      dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 4997, 128)    153728      dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_6 (Conv1D)               (None, 4996, 128)    192128      dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1D)  (None, 2499, 128)    0           conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_5 (MaxPooling1D)  (None, 2498, 128)    0           conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_6 (MaxPooling1D)  (None, 2498, 128)    0           conv1d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 319872)       0           max_pooling1d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_5 (Flatten)             (None, 319744)       0           max_pooling1d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_6 (Flatten)             (None, 319744)       0           max_pooling1d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 959360)       0           flatten_4[0][0]                  \n",
            "                                                                 flatten_5[0][0]                  \n",
            "                                                                 flatten_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 64)           61399104    concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 64)           0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 13)           845         dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 13)           0           dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 13)           0           dropout_6[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 63,361,133\n",
            "Trainable params: 63,361,133\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U9SciCgIT8c1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from keras.callbacks import TensorBoard\n",
        "import tensorflow as tf\n",
        "\n",
        "class TensorBoardColabCallback(TensorBoard):\n",
        "    def __init__(self, tbc=None, write_graph=True, name=None, **kwargs):\n",
        "        # Make the original `TensorBoard` log to a subdirectory 'training'\n",
        "\n",
        "        if tbc is None:\n",
        "            return\n",
        "\n",
        "        log_dir = tbc.get_graph_path()\n",
        "\n",
        "        training_log_dir = os.path.join(log_dir, 'training_{}'.format(name))\n",
        "        super(TensorBoardColabCallback, self).__init__(training_log_dir, **kwargs)\n",
        "\n",
        "        # Log the validation metrics to a separate subdirectory\n",
        "        self.val_log_dir = os.path.join(log_dir, 'validation_{}'.format(name))\n",
        "\n",
        "    def set_model(self, model):\n",
        "        # Setup writer for validation metrics\n",
        "        self.val_writer = tf.summary.FileWriter(self.val_log_dir)\n",
        "        super(TensorBoardColabCallback, self).set_model(model)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Pop the validation logs and handle them separately with\n",
        "        # `self.val_writer`. Also rename the keys so that they can\n",
        "        # be plotted on the same figure with the training metrics\n",
        "        logs = logs or {}\n",
        "        val_logs = {k.replace('val_', ''): v for k, v in logs.items() if k.startswith('val_')}\n",
        "\n",
        "        for name, value in val_logs.items():\n",
        "            # print('val_logs:',epoch, name, value)\n",
        "            summary = tf.Summary()\n",
        "            summary_value = summary.value.add()\n",
        "            summary_value.simple_value = value.item()\n",
        "            summary_value.tag = name\n",
        "            self.val_writer.add_summary(summary, epoch)\n",
        "        self.val_writer.flush()\n",
        "\n",
        "        # Pass the remaining logs to `TensorBoard.on_epoch_end`\n",
        "        logs = {k: v for k, v in logs.items() if not k.startswith('val_')}\n",
        "        super(TensorBoardColabCallback, self).on_epoch_end(epoch, logs)\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        super(TensorBoardColabCallback, self).on_train_end(logs)\n",
        "        self.val_writer.close()\n",
        "\n",
        "tb.TensorBoardColabCallback = TensorBoardColabCallback"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lTFqAwZM8F6z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def define_callbacks(name):\n",
        "  # Define the callbacks\n",
        "  log_dir = tbc.get_graph_path()\n",
        "\n",
        "  tbc_callback = tb.TensorBoardColabCallback(tbc, name=name)\n",
        "   \n",
        "  callbacks = [\n",
        "      ReduceLROnPlateau(),\n",
        "      EarlyStopping(patience=4),\n",
        "      tbc_callback\n",
        "  ]\n",
        "  return callbacks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R_VTGkTrVW6l",
        "colab_type": "code",
        "outputId": "c5ec85c6-fc85-4a73-eb59-8dd00d15f0a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "# Create an array of names\n",
        "network_names = []\n",
        "for p in network_parameters:\n",
        "  name = \"oversampling_{}_load_embeddings_{}_num_classes_{}_embeddings_size_{}_conv_size_{}_conv_filter_{}_dropout_{}_fnn_size_{}\".format(\n",
        "      p[\"oversampling\"], p[\"load_embeddings\"], p[\"num_classes\"], p[\"embeddings_size\"],\n",
        "      p[\"conv_size\"], p[\"conv_filter\"], p[\"dropout\"], p[\"fnn_size\"])\n",
        "  name = name.replace(\" \", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"-\")\n",
        "  network_names.append(name)\n",
        "  \n",
        "print(network_names)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['oversampling_False_load_embeddings_False_num_classes_None_embeddings_size_200_conv_size_128_conv_filter_3-4-5_dropout_0.1_fnn_size_64-13', 'oversampling_False_load_embeddings_False_num_classes_None_embeddings_size_300_conv_size_128_conv_filter_3-4-5_dropout_0.1_fnn_size_64-13']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aq68IX-Y807N",
        "colab_type": "code",
        "outputId": "494edfeb-af53-4af5-c1cf-a37c2d0440fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 946
        }
      },
      "cell_type": "code",
      "source": [
        "for i, net_model in enumerate(model_list):\n",
        "  print(\"\\n\\n********************************************\\n\")\n",
        "  print(network_names[i])\n",
        "  callbacks = define_callbacks(network_names[i])\n",
        "  # Fit the model and extract its data\n",
        "  if network_parameters[i][\"oversampling\"]:\n",
        "    history = net_model.fit(train_x_oversampled, train_y_oversampled, epochs=20, batch_size=32, \n",
        "                            class_weight=class_weight, callbacks=callbacks,\n",
        "                            validation_data=(test_x_token, test_y))\n",
        "  else:\n",
        "    history = net_model.fit(train_x_token, train_y, epochs=10, batch_size=32, \n",
        "                            class_weight=class_weight, callbacks=callbacks,\n",
        "                            validation_data=(test_x_token, test_y))\n",
        "\n",
        "  # Set a name for the model based on the tweaked parameters\n",
        "  p = network_parameters[i]\n",
        "  name = network_names[i]\n",
        "  # And save the model\n",
        "  net_model.save(SST_HOME+\"DL/models/\" + name)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "********************************************\n",
            "\n",
            "oversampling_False_load_embeddings_False_num_classes_None_embeddings_size_200_conv_size_128_conv_filter_3-4-5_dropout_0.1_fnn_size_64-13\n",
            "Train on 202 samples, validate on 30 samples\n",
            "Epoch 1/10\n",
            "202/202 [==============================] - 5s 26ms/step - loss: 2.3735 - categorical_accuracy: 0.0297 - val_loss: 1.3839 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "202/202 [==============================] - 3s 13ms/step - loss: 1.0469 - categorical_accuracy: 0.0248 - val_loss: 0.5305 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "202/202 [==============================] - 3s 13ms/step - loss: 0.5106 - categorical_accuracy: 0.0149 - val_loss: 0.6219 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "202/202 [==============================] - 3s 13ms/step - loss: 0.5552 - categorical_accuracy: 0.0050 - val_loss: 0.5572 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "202/202 [==============================] - 3s 13ms/step - loss: 0.4443 - categorical_accuracy: 0.0050 - val_loss: 0.4847 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "202/202 [==============================] - 3s 13ms/step - loss: 0.3787 - categorical_accuracy: 0.0248 - val_loss: 0.4866 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "202/202 [==============================] - 3s 13ms/step - loss: 0.3192 - categorical_accuracy: 0.0149 - val_loss: 0.4742 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "202/202 [==============================] - 3s 14ms/step - loss: 0.2611 - categorical_accuracy: 0.0149 - val_loss: 0.4737 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "202/202 [==============================] - 3s 13ms/step - loss: 0.2062 - categorical_accuracy: 0.0248 - val_loss: 0.4893 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "202/202 [==============================] - 3s 13ms/step - loss: 0.1657 - categorical_accuracy: 0.0495 - val_loss: 0.5081 - val_categorical_accuracy: 0.0000e+00\n",
            "\n",
            "\n",
            "********************************************\n",
            "\n",
            "oversampling_False_load_embeddings_False_num_classes_None_embeddings_size_300_conv_size_128_conv_filter_3-4-5_dropout_0.1_fnn_size_64-13\n",
            "Train on 202 samples, validate on 30 samples\n",
            "Epoch 1/10\n",
            "202/202 [==============================] - 6s 28ms/step - loss: 2.3747 - categorical_accuracy: 0.1980 - val_loss: 1.9889 - val_categorical_accuracy: 0.0667\n",
            "Epoch 2/10\n",
            "202/202 [==============================] - 3s 17ms/step - loss: 1.6148 - categorical_accuracy: 0.0248 - val_loss: 0.5352 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "202/202 [==============================] - 3s 17ms/step - loss: 0.5811 - categorical_accuracy: 0.0248 - val_loss: 0.6680 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "202/202 [==============================] - 3s 17ms/step - loss: 0.6272 - categorical_accuracy: 0.0050 - val_loss: 0.6239 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "202/202 [==============================] - 3s 16ms/step - loss: 0.5020 - categorical_accuracy: 0.0248 - val_loss: 0.4576 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "202/202 [==============================] - 3s 16ms/step - loss: 0.4203 - categorical_accuracy: 0.0050 - val_loss: 0.4680 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "202/202 [==============================] - 3s 17ms/step - loss: 0.3733 - categorical_accuracy: 0.0099 - val_loss: 0.4718 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "202/202 [==============================] - 3s 17ms/step - loss: 0.3152 - categorical_accuracy: 0.0198 - val_loss: 0.4800 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "202/202 [==============================] - 3s 17ms/step - loss: 0.2746 - categorical_accuracy: 0.0248 - val_loss: 0.4721 - val_categorical_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gjX1yHqChuLx",
        "colab_type": "code",
        "outputId": "37af1cac-c48c-4df1-cc19-ca2cbd5b2ca9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "class B:\n",
        "  def __init__(self,):\n",
        "    print('Im B')\n",
        "    \n",
        "class A(B):\n",
        "  def __init__(self,):\n",
        "    super().__init__()\n",
        "   \n",
        "a = A()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Im B\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mcSt47P389_j",
        "colab_type": "code",
        "outputId": "74759f23-89f8-4336-967d-f1fed9e37d16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "predictions_list = []\n",
        "for i, net_model in enumerate(model_list):\n",
        "  print(\"\\n\\n********************************************\\n\")\n",
        "  print(network_names[i])\n",
        "\n",
        "  predictions = net_model.predict(test_x_token)\n",
        "  predictions = np.array([[0 if value < 0.5 else 1 for value in prediction] for prediction in predictions])\n",
        "  predictions_list.append(predictions)\n",
        "  # measuring performance on test set\n",
        "  cr=classification_report(test_y, predictions, target_names=CATEGORIES.values)\n",
        "  print(cr)\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "********************************************\n",
            "\n",
            "oversampling_False_load_embeddings_False_num_classes_None_embeddings_size_200_conv_size_128_conv_filter_3-4-5_dropout_0.1_fnn_size_64-13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "     ASP-FOR-MI       0.77      1.00      0.87        23\n",
            "      ABDOMINAL       0.00      0.00      0.00        11\n",
            "  DIETSUPP-2MOS       0.55      0.69      0.61        16\n",
            "   ADVANCED-CAD       0.60      0.94      0.73        16\n",
            "       KETO-1YR       0.00      0.00      0.00         0\n",
            " MAJOR-DIABETES       0.56      0.88      0.68        16\n",
            "          HBA1C       0.67      0.20      0.31        10\n",
            "MAKES-DECISIONS       0.93      1.00      0.97        28\n",
            "  ALCOHOL-ABUSE       0.00      0.00      0.00         1\n",
            "        ENGLISH       0.90      1.00      0.95        27\n",
            "     DRUG-ABUSE       0.00      0.00      0.00         2\n",
            "     CREATININE       0.00      0.00      0.00         9\n",
            "        MI-6MOS       0.00      0.00      0.00         2\n",
            "\n",
            "      micro avg       0.73      0.75      0.74       161\n",
            "      macro avg       0.38      0.44      0.39       161\n",
            "   weighted avg       0.63      0.75      0.67       161\n",
            "    samples avg       0.74      0.76      0.73       161\n",
            "\n",
            "\n",
            "\n",
            "********************************************\n",
            "\n",
            "oversampling_False_load_embeddings_False_num_classes_None_embeddings_size_300_conv_size_128_conv_filter_3-4-5_dropout_0.1_fnn_size_64-13\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "     ASP-FOR-MI       0.77      1.00      0.87        23\n",
            "      ABDOMINAL       0.33      0.09      0.14        11\n",
            "  DIETSUPP-2MOS       0.50      0.38      0.43        16\n",
            "   ADVANCED-CAD       0.53      1.00      0.70        16\n",
            "       KETO-1YR       0.00      0.00      0.00         0\n",
            " MAJOR-DIABETES       0.56      0.56      0.56        16\n",
            "          HBA1C       0.60      0.30      0.40        10\n",
            "MAKES-DECISIONS       0.93      1.00      0.97        28\n",
            "  ALCOHOL-ABUSE       0.00      0.00      0.00         1\n",
            "        ENGLISH       0.90      1.00      0.95        27\n",
            "     DRUG-ABUSE       0.00      0.00      0.00         2\n",
            "     CREATININE       0.33      0.11      0.17         9\n",
            "        MI-6MOS       0.00      0.00      0.00         2\n",
            "\n",
            "      micro avg       0.72      0.71      0.71       161\n",
            "      macro avg       0.42      0.42      0.40       161\n",
            "   weighted avg       0.66      0.71      0.66       161\n",
            "    samples avg       0.73      0.72      0.71       161\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dnNlIl7YWSxw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#**Generating output in XML format**\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "X3xiVEPqLkF5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree\n",
        "import os\n",
        "NOT='not met'\n",
        "MET='met'\n",
        "\n",
        "#gets a idFile, a dictionary with the predictions (category, label) and the name of the classifier used.\n",
        "def outputToXML(idFile, dictPred, classifier):\n",
        "    \n",
        "    path=SST_HOME+'data/test/xml/'+idFile+'.xml'\n",
        "    output_dir = SST_HOME+'data/output/'+classifier\n",
        "    \n",
        "    output = output_dir+'/'+idFile+'.xml'\n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "      print(\"\\n\\nmaking dir\")\n",
        "      s = os.makedirs(output_dir)\n",
        "      print(output_dir)\n",
        "      print(s)      \n",
        "   \n",
        "    et = xml.etree.ElementTree.parse(path)\n",
        "\n",
        "    new_tag = xml.etree.ElementTree.SubElement(et.getroot(), 'TAGS')\n",
        "    \n",
        "    for cat in dictPred.keys():\n",
        "        element = xml.etree.ElementTree.SubElement(new_tag, cat)    \n",
        "        if dictPred[cat]==0:\n",
        "            element.attrib['met'] = NOT \n",
        "        else:\n",
        "            element.attrib['met'] = MET\n",
        "\n",
        "    et.write(output)\n",
        "\n",
        "#function for creating a dictionary with the categories with values 0 or 1\n",
        "def iniDictPred(labels, categories):\n",
        "    \n",
        "    if len(labels)!=len(categories):\n",
        "        print('Warning!!!')\n",
        "        return None\n",
        "    \n",
        "    dictPred={}\n",
        "    i=0\n",
        "    \n",
        "    for x in categories:\n",
        "        dictPred[x]=labels[i]\n",
        "        i=i+1\n",
        "    return dictPred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4RxszYeCwl0Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "385acd83-8829-409d-ff37-c49396418f9d"
      },
      "cell_type": "code",
      "source": [
        "#creates the output xml files per training\n",
        "for i, predictions in enumerate(predictions_list):\n",
        "  dictionary = zip(IDFILES, predictions)\n",
        "  for obj in dictionary:\n",
        "      idFile=str(obj[0][0])\n",
        "      labels=obj[1] #gets their predictions for this file\n",
        "      dictPred=iniDictPred(labels, CATEGORIES) #creates a dictionary to join categories and labels 0,1\n",
        "      outputToXML(idFile,dictPred,\"CNN/{}\".format(network_names[i]))\n",
        "\n",
        "  print('output xml files were generated!')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output xml files were generated!\n",
            "output xml files were generated!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9jHMPR6mDLCG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "947cac45-0d64-4607-a940-6688a1b2d6ae"
      },
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "# Writes the output in a file for each training.\n",
        "for i, name in enumerate(network_names):\n",
        "  print(name) \n",
        "  path = \"data/output/CNN/\"\n",
        "  n = path + \"{}\".format(name)\n",
        "  os.system('cd \"{}\" && echo \"{}\" {} {}results.txt'.format(SST_HOME, name, \">\" if i == 0 else \">>\", path))\n",
        "  os.system('cd \"{}\" && python3 track1_eval.py data/test/gold {} >> {}results.txt'.format(SST_HOME, n, path))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "oversampling_False_load_embeddings_False_num_classes_None_embeddings_size_200_conv_size_128_conv_filter_3-4-5_dropout_0.1_fnn_size_64-13\n",
            "oversampling_False_load_embeddings_False_num_classes_None_embeddings_size_300_conv_size_128_conv_filter_3-4-5_dropout_0.1_fnn_size_64-13\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}