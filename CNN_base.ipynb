{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN-base.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PRaezUC3M/cohort_selection/blob/master/CNN_base.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "VUhjUt2_2taj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Mount the drive folder**"
      ]
    },
    {
      "metadata": {
        "id": "HA9j8Odl20Qj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Load the train and test csv files**"
      ]
    },
    {
      "metadata": {
        "id": "XsZ86gUk2ne4",
        "colab_type": "code",
        "outputId": "d00a06c4-db58-4ffa-c45b-f79a7ce7fccc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vluB44afpEHL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Configurartion of the experiments**\n",
        "The different possible experiments have been automated. It is inspired in grid-search, and the parameters must be expressed in array-like style. You can find an example below."
      ]
    },
    {
      "metadata": {
        "id": "AdJIJMn1pbCa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Baseline Model\n",
        "num_classes = 13\n",
        "\n",
        "embeddings_size = [200]\n",
        "conv_size = [128]\n",
        "conv_filter = [4]\n",
        "dropout = [0.1]\n",
        "fnn_size = [conv_size[-1] // 2, num_classes]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K-Emhq-R2tLE",
        "colab_type": "code",
        "outputId": "d2c6d770-c909-439f-95e8-98af9a239bb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "SST_HOME='drive/My Drive/Colab Notebooks/CohortSelection/'\n",
        "\n",
        "def load_train():\n",
        "  path_train=SST_HOME+'data/train/train.csv'\n",
        "  train = pd.read_csv(path_train,header=0, delimiter=\"\\t\", quoting=3)\n",
        "\n",
        "  categories=train.columns[2:]\n",
        "\n",
        "  texts = train[['TEXT']].as_matrix()\n",
        "  train_x = [x[0].strip() for x in texts.tolist()]\n",
        "\n",
        "  #we only keep the columns with the categories.\n",
        "  train_y = train.drop(['IDFILE', 'TEXT'], axis=1).as_matrix()\n",
        "\n",
        "\n",
        "  print('training loaded')\n",
        "  \n",
        "  return train_x, train_y, categories\n",
        "\n",
        "def load_test():\n",
        "  path_test=SST_HOME+'data/test/test.csv'\n",
        "  test = pd.read_csv(path_test,header=0, delimiter=\"\\t\", quoting=3)\n",
        "  #gets the ids\n",
        "  idFiles = test[['IDFILE']].as_matrix().tolist()\n",
        "  #gets the texts\n",
        "  texts = test[['TEXT']].as_matrix()\n",
        "  test_x = [x[0].strip() for x in texts.tolist()]\n",
        "  #gets the labels\n",
        "  test_y = test.drop(['IDFILE', 'TEXT'], axis=1).as_matrix()\n",
        "\n",
        "  print('testing dataset loaded')\n",
        "  \n",
        "  return test_x, test_y, idFiles\n",
        "  \n",
        "train_x, train_y, categories = load_train()\n",
        "test_x, test_y, idFiles = load_test()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training loaded\n",
            "testing dataset loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uaDhdU7pY7Qv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Oversampling**\n",
        "\n",
        "As the dataset is very unbalanced, we must perform over-sampling (which is to increase the minority class(es)). The RandomOverSampler **class** allows us to over-sample minority classes by  picking samples at random with replacement. We need to install the package **imbalanced-learn**.\n"
      ]
    },
    {
      "metadata": {
        "id": "4SRFMvOVZNfa",
        "colab_type": "code",
        "outputId": "fb718024-82f3-4ede-a3af-c4dfb75e6e28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 install -U imbalanced-learn"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting imbalanced-learn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/4c/7557e1c2e791bd43878f8c82065bddc5798252084f26ef44527c02262af1/imbalanced_learn-0.4.3-py3-none-any.whl (166kB)\n",
            "\u001b[K    100% |████████████████████████████████| 174kB 7.0MB/s \n",
            "\u001b[?25hCollecting scikit-learn>=0.20 (from imbalanced-learn)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/26/d04320c3edf2d59b1fcd0720b46753d4d603a76e68d8ad10a9b92ab06db2/scikit_learn-0.20.1-cp36-cp36m-manylinux1_x86_64.whl (5.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.4MB 7.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.14.6)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.1.0)\n",
            "Installing collected packages: scikit-learn, imbalanced-learn\n",
            "  Found existing installation: scikit-learn 0.19.2\n",
            "    Uninstalling scikit-learn-0.19.2:\n",
            "      Successfully uninstalled scikit-learn-0.19.2\n",
            "Successfully installed imbalanced-learn-0.4.3 scikit-learn-0.20.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FS2hBEscZQSL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "from imblearn.over_sampling import RandomOverSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2meJcHd82-6W",
        "colab_type": "code",
        "outputId": "d8ce624d-bb37-4d7a-e340-d440c6cce597",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "train_y[0]\n",
        "\n",
        "multilabel_multiclass_y = np.array([[(index + 1) for index, value in enumerate(y) if not value == 0] for y in train_y])\n",
        "multilabel_multiclass_y[:10]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list([1, 3, 4, 6, 7, 8, 10, 12]), list([1, 2, 3, 4, 8, 10]),\n",
              "       list([1, 4, 6, 8, 10, 12]), list([1, 8, 10, 11]),\n",
              "       list([1, 3, 4, 6, 8, 9, 10, 12]), list([1, 2, 4, 8, 10]),\n",
              "       list([1, 2, 3, 8, 10, 12]), list([1, 4, 6, 8, 10, 12]),\n",
              "       list([1, 2, 3, 4, 6, 7, 8, 10]), list([1, 3, 4, 6, 8, 10, 12, 13])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "ywzRr7Z_lbxP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d42cd67d-85fc-42d9-b668-b70ee8d24df7"
      },
      "cell_type": "code",
      "source": [
        "any([len(i) == 0 for i in multilabel_multiclass_y])\n",
        "len(np.where(~train_y.any(axis=1))[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "Sj6oq5ZpZLy5",
        "colab_type": "code",
        "outputId": "f6b60f15-b81c-4c02-8944-8cde09f826b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "cell_type": "code",
      "source": [
        "ros = RandomOverSampler(random_state=9000)\n",
        "X_resampled, Y_resampled = ros.fit_resample(train_x_token, train_y.astype(np.float64))\n",
        "\n",
        "assert Y_resampled.shape[1] == train_y.shape[1]\n",
        "\"\"\"Compare both datasets (before oversampling) and after sampling)\"\"\"\n",
        "\n",
        "# Check Y_resampled has the same lables\n",
        "assert Y_resampled.shape[1] == train_y.shape[1]\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "fig = plt.figure(figsize=(20,20))\n",
        "(ax_test, ax_train) = fig.subplots(ncols=2, nrows=1)\n",
        "g1 = sns.barplot(x=train_y.sum(axis=0), y=categories, ax=ax_test)\n",
        "g2 = sns.barplot(x=Y_resampled.sum(axis=0), y=categories, ax=ax_train)\n",
        "g1.set_title(\"class distribution before resampling\")\n",
        "g2.set_title(\"class distribution in training set after resampling\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-223-f5ea5cd1e81e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_resampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mros\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mY_resampled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\"\"\"Compare both datasets (before oversampling) and after sampling)\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "mfK0DBRqNVeL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#**Balancing the categories**\n",
        "We can see that there are some categories way more present than others in our dataset. Let's sort them."
      ]
    },
    {
      "metadata": {
        "id": "ABuXlWNYMuow",
        "colab_type": "code",
        "outputId": "a00ed187-c8d5-4a89-813d-6e0146390c73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "cell_type": "code",
      "source": [
        "classes = np.add(sum(train_y), sum(test_y))\n",
        "import matplotlib.pyplot as plt\n",
        "print(classes)\n",
        "plt.plot(classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[185  88 121 141   1 129  77 222   8 219  14  91  20]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f3a9c82ee48>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAFKCAYAAADMuCxnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzs3XmUZFWVP/rvvTHdmCMyhhyqcqgs\nCqgZEJACCkWKBrRRBBW6Hrh8bf9e2097YbcutX39e/pbLOkW+3W3/GQ1Nirtgsd69bO0lR6L1m6k\nwKJASmsEasiqnDOGzJjn4b4/Im9EZlYOEZE37rg//yhRGRGnbkXGvuecffZmeJ7nQQghhBBZsXIP\ngBBCCCEUkAkhhBBFoIBMCCGEKAAFZEIIIUQBKCATQgghCkABmRBCCFEAo5xvHomkRH09r9eGWCwr\n6muqGV2Pxeh6NNC1WIyux2J0PRrEvhaBgHPFP9PUDNloNMg9BEWh67EYXY8GuhaL0fVYjK5Hg5TX\nQlMBmRBCCFErCsiEEEKIAlBAJoQQQhSAAjIhhBCiABSQCSGEEAWggEwIIYQoAAVkQgghRAEoIBNC\nCCEKQAGZEEIIUQAKyIQQQogCUEAmhMhiMprB2fG43MMgRDEoIBNCZPG9fzqDv/lfx1Gt8nIPhRBF\noIBMCJFcqVzFRCSNQqmCWKog93AIUQQKyIQQyU1FM6jMz4yjiZzMoyFEGSggE0IkNxpq9EKPJvIy\njkQZKtUq/uHf3sHbozG5h0JkZJR7AIQQ/RkPpev/PxKnGfJYKI1Xjk8hWyhj66BX7uEQmdAMmRAi\nudEwzZAXEm5KIjG6OdEzCsiEEElVeR7j4TS6u2xgAERphtwIyHQtdI2WrAkhkorEcigUKxjudaJU\nriBCM+T6KkG2UEYmX4KdM8k8IiIHmiETQiQlJHT1B53wu62Ipwoolasyj0peC1cJwrRsrVsUkAkh\nkhoP1xK6BrsdCLg58ADmkvqeJUfi+QX/nwKyXlFAJoRIqj5D7nbC77ECACI6PotcrfKYTVJAJhSQ\nCSESGw+l4XNZ4LCa4HdzAPSdaR1LFVCp8hgIOgBQQNYzCsiEEMkk0gUkMkUMdDsBoBGQ4/oNyEIA\nvnr+/HFEx9dC7yggE0IkMza/f9w/PxsMzC9Z67l8prBc3+e3w+Mw0wxZxyggE0IkMza/fzw4P0P2\nOCwwsIyuZ4XC3z3gsSLgsWI2mUe5ou+sc72igEwIkczYfMnM/u7aDJllGfjcnK5nyMLfPeDmEPRY\nwfNYlORF9IMCMiFEMmOhFOycET4XV38s4OaQypaQL5ZlHJl8ovE8WIaB12WpL+HTsrU+UUAmhEgi\nVygjHMuhP+gAwzD1x/31fWR9zgoj8Rx8bgsMLNsIyFQcRJcoIBNCJDERSYMH6hnWAj1nWhdLFSQy\nRfjdtUAc8AozZP1dC0IBmRAiEWH/eGB+/1gQ0HFxEGFVIODh5v+Xlqz1jAIyIUQSQob15TPk+SVr\nHc4KhcArBGKXzQSLyYAwBWRdooBMCJHEWCgNo4FFT5dt0eONal36C0LCDFm4KWEYBgEPh0g8B57n\n5RwakQEFZEJIx5UrVUxG09gYsMNoWPy147SZYDaxukzqEmbIfs+CrHOPFfliBelcSa5hEZlQQCaE\ndNz0bBblCn/ZcjUwPyt0WxFN6G9WuHTJeuH/p2Vr/TE280NPPPEE3nrrLZTLZfzhH/4hdu7ciS99\n6UuoVCoIBAL41re+BbPZjBdffBE//OEPwbIsPvGJT+DjH/94p8dPCFGBxv6xY9k/97s5TEYzyOTL\ncFhNUg5NVtFEHhaTAc4Ff+eFiV2b+9xyDY3IYM2A/Prrr+PcuXM4cOAAYrEYPvrRj2LPnj3Yv38/\n7rnnHvz1X/81Dh48iPvuuw9PPfUUDh48CJPJhI997GO488474fF4pPh7EEIUrJFhffkMGVh4Fjmn\nm4DM8zwi8RwCHm7RuexGQNbfEr7erblkfcMNN+Db3/42AMDlciGXy+Ho0aO44447AAC33347jhw5\nguPHj2Pnzp1wOp3gOA7XXXcdjh071tnRE0JUYTycAgNgY8C+7J8HdHgWOZMvI1+s1BO6BMIRKCoO\noj9rzpANBgNstlpW5MGDB3Hbbbfh1VdfhdlsBgD4fD5EIhFEo1F0dXXVn9fV1YVIJLLqa3u9NhiN\nhvWM/zKBwPJ34HpF12Mxuh4NUl0LnucxHsmgL+BA/wbvsj8zPFD77siVq7L9G0n9vvHxGABgoNe1\n6L09XhsYBohni7J+Xul3pUGqa9HUHjIA/PznP8fBgwfxgx/8AL/zO79Tf3ylJIxmkjNisWyzb9+U\nQMCJSCQl6muqGV2Pxeh6NEh5LSLxHDK5ErYPeVd8TzNT+764NJmQ5d9Ijs/G2YuzAAC7xXDZe3ud\nFkyG07J9Xul3pUHsa7FacG8qy/rw4cN4+umn8cwzz8DpdMJmsyGfry0thUIhBINBBINBRKPR+nPC\n4TCCweA6h04IUbu19o8BfVbrqlfpWrJkLTwWTxVQKlekHhaR0ZoBOZVK4YknnsB3v/vdeoLWzTff\njEOHDgEAXnrpJezduxe7d+/GyZMnkUwmkclkcOzYMVx//fWdHT0hRPHqGdbB5TOsAcBqMcLOGTGr\no7PI0WXOIAsCXit46Lfhhl6tuWT9r//6r4jFYvj85z9ff+wv//Iv8ed//uc4cOAA+vr6cN9998Fk\nMuELX/gCPv3pT4NhGHz2s5+F00l7EITo3Xh47RkyUKtWNTWbAc/zi7KOtap+Bnm5GfKCo0+9vuUT\n4Yj2rBmQH3zwQTz44IOXPf7ss89e9tjdd9+Nu+++W5yREUI0YTSUgsdhhstuXvXn/B4Oo6EUEpki\nPA6LRKOTTySRr9WuNl+e2FrPtNZR1jmhSl2EkA5KZYuIpQprzo6BxkxRD0efqlUes4l8/fz1UkFP\n7WQLdX3SFwrIhJCOGQsv33JxOcJeqh4Su2KpAipVflHJzIWEGXKYziLrCgVkQkjHjAsZ1sG1Z8iN\nNozaD0JCZyuh09VSDqsJnNmgi5sT0kABmRDSMWvVsF6ovm+qg8zi8DJNJRZiGAZBj5XaMOoMBWRC\nSMeMhlLgzIYV90oXqvdF1sMMOS6cQV5+hgzUgnWxVEUyU5RqWERmFJAJIR1RKFUwM5fFQNABtolj\nTCajAW6HWRdnb+tL1qvcqFCTCf2hgEwI6YiJSBo8D/Q3kWEtCLitmEsWUKlWOzgy+UXiebAMgy7X\nyse7At7GWWSiDxSQCSEdUU/oamL/WOB3c6jyPGLJQqeGpQiRRA5dLgsM7MpfwfVMawrIukEBmRDS\nEY2Smc3PkP06SOwqlipIpIsrJnQJFlbrIvpAAZkQ0hFj4TQMLIMNK/RAXo4ejj7Vm0osU8N6IZ+L\nA8NQQNYTCsiEENFVqzwmwmls8NthNDT/NSNkHWt5htw4g7z6DNloYOFzcbRkrSMUkAkhopuZy6JY\nrqK/hf1joJF1HNVwQQwha3q5Lk9LBTxWJNJFFErUhlEPNBOQT1yYxR/+xc8xl9TunTUhatEoCNJa\nx7culwUsw2i6nnVkjaIgCwXqNyjavR6kQTMBOZkpYiqawa/fCcs9FEJ0r17DepUeyMsxsCy6XBZN\nl4ys7yGvsWQNLKheRjWtdUEzAXn7pi4AwMmLczKPhBAizJD7W8iwFvjdHBLpIooaXaaNxHOwmAxw\n2kxr/ixlWuuLZgKy12nBpj4X3h2L034LITLieR5joTQCHg42bs2W65cR9pFnNbj9xPM8ookc/B4O\nTBPVy4JUHERXNBOQAeC6q4IoV6p4dywm91AI0a1YqoB0rtTy/rFAyLTW4r5pJl9GrlBparkaaMyQ\nKdNaHzQVkN+ztRsAcPICLVsTIpexUHv7xwItn0UWZrrNZFgDgJ0zwWYx0gxZJzQVkLcOdYEzG3Dy\n4qzcQyFEt8bC7WVYC7RcrauVhC5BwGtFNJFHldowap6mArLRwGLbUBfCsRxCsazcwyFEl+oz5HYD\nsoZnyNEWZ8hAbdm6VK4ikaY2jFqnqYAMADuG57OtL9AsmRA5jIVScNpM8DjMbT3f7TDDaGA1OUNu\n5QyyoH70SYM3KGQxzQXkXcM+AMApOv5EiOSy+RKiiTwGup1NZREvh2UY+N2cJmfIwk2G3938DDlI\nR590Q3MBucvFYYPfjndGYyiV6fgTIVIab7MgyFJ+DzefkVwWY1iKEY3n4LSZwJmbPw5Wz7Sm4iCa\np7mADNSWrYvlKt4dj8s9FEJ0ZXSd+8cCIelJS7PCapVHNJFvabkaWFAcRMPVy0iNJgPyzvllazr+\nRIi0GjWs1z9DBrR1FjmeLqBS5VtargZq9b0NLKOpmxOyPE0G5C0bPbCYDDhFx58IkdRYKA2ziUW3\n17au1wloMNO6nYQuoFbf2+fiqJ61DmgyIJuMLLYOejE9m9XULzQhSlYqVzE9m0F/wAGWbS+hS+DT\nYLUuoe1iqwG59hwOyWwJ+aK29tTJYpoMyMCC408jNEsmRApT0QwqVX7d+8eANtsOCj2eW12yBoDA\n/IqDlttSEg0H5Po+8gjtIxMihVGhw9M6948BwM4ZwZkNmkpkanfJuvacWhCnmtbaptmAHPBY0dNl\nw9ujMZTKVbmHQ4jmjc9nWA+KMENmGAZ+txXReB68RkpGRhJ5sAyDLpel5edqMeucXE6zARmoLVsX\nShWcn6DjT4R02mg4BZZhsMFvF+X1Ah4OhVIFqVxJlNeTWzSem8+Ybv1rl9ow6oOmA/IuWrYmRBJV\nnsd4OI1enw1mk0GU12zUtFb/vmmxVEE8XWxruRpoXAtastY2TQfkK/s9MBlZ6v5ESIdFYjkUipV1\nnz9eqHEWWf1BaDbZesnMhWycEQ6rqZ6pTbRJ0wHZbDLg6gEvJiMZzCXpg0xIp9QTuoLr3z8WaGnf\nVAik/jZnyEAtL2Y2kUO1qo09dXI5TQdkANhJx58I6TihhvVgR2bI6r+ZbmRYtzdDFp5brvCIpQpi\nDYsojA4C8nz3J9pHJqRjGkeexJsh+zVUHERYdhdm/e0IUNcnzdN8QO7usiHoseLM6BzKFTr+REgn\njIfS8LkscFhNor0mZ67tm2qh2t56qnQJqA2j9mk+IAO140+5QgUXJhNyD4UQzUmkC0hkiqLuHwsC\nHg6zyTyqKj+LHI3nYDaxcNrav2Gpt2GkgKxZugjIVLWLkM4ZE3ogi7h/LPC7rShXeMRVvG/K8zwi\niRwCbisYpv0a37RkrX26CMhXD3hhNDA4RYldhIiu0XJR/BmyFhK7MvkycoXKuparAcDrtMBoYOjo\nk4bpIiBbzAZc1e/BWDiNeFq9d9qEKNFYqHMzZC0cfVpPU4mFWJaBz21V9bUgq9NFQAYWLlvTLJkQ\nMY2FUrBzRvhc6ws4y9HCDDkqwhlkQdBjRTpXQjZPbRi1SDcBeQcdfyJEdLlCGeFYDv1Bx7r2R1cS\nqJfPVO+sUIwzyIKAhqqXkcvpJiD3+mzwuTicvjiHSpWOPxEiholIGjw6s38MAF0uDgxqnZLUShj7\nes4gC+qZ1jEKyFqkm4DMMAx2DnchWyjj4lRK7uEQogmd3D8GAJORhcdpUfWMUJjd+0WYIdfPIqv4\nepCV6SYgA4195BO0j0yIKDqZYS3wuznEUgXVFvaJxHNw2kzgzMZ1v1bj6JN6VwzIynQVkK8e9MLA\n0vEnQsQyFkrDaGDR02Xr2Hv43VbwPFTZIKbK85hN5uvtE9dLmGVHYllRXo8oi64CstVixJaNblya\nSSGZKco9HEJUrVypYjKaxsaAHUZD575KhEQmNe4jx1MFlCu8KAldQK2cqMtuphmyRukqIAPAzs3z\n2dbUI5mQdZmezaJc4Tu2fyzwqzjTupFhLc4MufZatXKilJyqPfoLyJvo+BMhYpBi/xhYeNRHfbNC\nYczrLQqyUMBjRaXKYy5JRY60RncBeUPADq/TglMX56jRNyHr0Miw7mxA9qu4WlcnZsjU9Um7dBeQ\nGYbBjk1dSOdKuDRDx58Iadd4OAUGwMaAvaPv43VaYGAZVc6QIyJW6RJQ1yftaiognz17Fvv27cPz\nzz8PAPjKV76Ce++9F4888ggeeeQRvPzyywCAF198EQ888AA+/vGP40c/+lHHBr1eVEaTkPXheR5j\noTS6u2yiHOdZDcsy8Lk4Ve4hRxM5MAzQ5bSI9prU9Um71vxNymazeOyxx7Bnz55Fj//pn/4pbr/9\n9kU/99RTT+HgwYMwmUz42Mc+hjvvvBMej0f8Ua/TtiEvWKZ2/Okjt26SeziEqE40kUe2UMaO4S5J\n3s/v4XDmUgyFYgUWs0GS9xRDJJ6Dz8WJmoVOZ5G1a81PidlsxjPPPINgMLjqzx0/fhw7d+6E0+kE\nx3G47rrrcOzYMdEGKiYbZ8IVG1wYmUoinSvJPRxCVEeq/WNBPdNaRWeRS+UK4umiqAldAOB2mGEy\nsohQ+UzNWTMgG41GcNzlH6jnn38en/zkJ/Enf/InmJubQzQaRVdX4265q6sLkUhE3NGKaOdmH3jQ\n8SdC2lHPsA529siTQAhqalq2rmdYi7h/DAAsw8Dv5mjJWoPa2vz5yEc+Ao/Hg61bt+Lv//7v8Z3v\nfAfXXnvtop/h+bUzmL1eG4xGcZefAoHm7tj3XtePH/9yBOenUrj3fVtEHYOSNHs99IKuR8N6rkVo\nfrn0mm098DrFb7u41HC/FwCQr/Ad+zcU+3VHo7VqWkMb3KK/9sZuJ6ZnQ7DaLXDYzKK+toB+Vxqk\nuhZtBeSF+8kf+MAH8PWvfx133XUXotFo/fFwOIxrrrlm1deJiVz+LRBwIhJpLnPaaWbhtpvx6zMz\nCIWTYDvQOk5urVwPPaDr0bDea3FuPAa3w4xyvoRIvvPbPpb5tbyLE/GO/Bt24rNxYaxW68BmZEV/\nbbfVBAA4cz6CTb0uUV8boN+VhcS+FqsF97YyDf74j/8Y4+PjAICjR49iy5Yt2L17N06ePIlkMolM\nJoNjx47h+uuvb2/EEhCOPyWzJYzP74cRQtaWyhYRSxUwKNH+MdBY9lXT0adoB448CSjTWpvWnCGf\nOnUK3/zmNzE5OQmj0YhDhw7h4Ycfxuc//3lYrVbYbDb8xV/8BTiOwxe+8AV8+tOfBsMw+OxnPwun\nU9lLHjs3+/DaqRmcGJnFYI+yx0qIUoyFazew/RLtHwOAy2aC2cSqag+5E0VBBAEvBWQtWjMg79ix\nA88999xlj991112XPXb33Xfj7rvvFmdkEtg21AWGqZ1HvvfmIbmHQ4gqCCtKUs6QGYaB321VVYOJ\nSCIHs4mFy2YS/bVphqxNuqvUtZDDasJwnwsXJhPISLAPRogWNGpYSzdDBmqZ1rlCWTW/q5F4HgG3\nFUwH8lMC81nndBZZW3QdkIFa1S6eB85cisk9FEJUYSycBmc2dGRvdDWBetcn5QehTL6EXKEs+hlk\ngdlkgMdhphmyxlBApjKahDStUKpgejaDgaBD8pMJfqEvsgqCUCcTugQBjxWzyTzKFWrDqBW6D8iD\nPU44rCacGplt6uw0IXo2EUmD54F+CfePBfXiICrYR+5kQpcg4LGC54FZFVUvI6vTfUBmGQY7hrsQ\nTxcxEcnIPRxCFG28XjJT2v1jYEH5zITyZ8iR+TEGOrRkDVAbRi3SfUAGaNm6U2bmsvjOT07iV6em\n5R4KEUmjZKb0M+SARz0zZKmWrAFQTWsNoYAMYPumLjAATl6ggCwGnufx2slp/I9n38SxsxG89Oa4\n3EMiIhkLp2FgGWzocA/k5dg4E2wWoypmhMIYO5XUBVDXJy3qbCNTlXDZzBjqdeL8ZAK5QhlWC12W\nduUKZTx36F28fiYEq8UAt8OMyUgGpXIVJiPd/6lZtcpjIpxGn98uajvBVvg9HGZms+B5viPHicQS\nSeThsJo6+l1CxUG0h74h5+0c9qFS5en40zqMTCXx9WffwOtnQhjuc+Fr//uNuHZLAJUqj6ko7c+r\n3cxcFsVyVZb9Y0HAbUWxXEUyU5RtDGup8jxmE7n6EnunCNXLwhSQNYMC8rwd8/vI1I6xdVWex7+9\nPoq/eP4tRON5fGjPIL7yv12HoMeKofmSpJdmkjKPkqxXoyCIfGVm60efFLyPHE8VUK7wHc2wBmrV\nywIeKyLxHJ0Q0Qham5033OuCnTPi5PzxJyUvhylJIl3A9/75DE5fqnX/+W+/uw3bhhp9sYXyiqPU\nwEP1hBrWUvVAXk490zqewxUb3LKNYzX1PsjuzhdOCXqsmIxkkM6V4OxQG0YiHQrI81iWwfZNXXjj\n7TCmZrPY4Jc+aUVtTlyYxff/5QxS2RJ2bfbh9z+0Fa4lXwp9fjsMLIPRGWrlpnbCDLlfhgxrQUAF\nM+TGGeTO94kWZuHheI4CsgbQkvUC9eNPlG29qlK5iv/vF+fwtz86jlyhjN+7Ywse/diuy4IxAJiM\nLDYGHBgPp6mikIrxPI+xUBoBDwcbJ999vDDrnFXwWeR6hrUEpUWpyYS2UEBeYMem2lIrnUde2cxc\nFo8/9xZeenMc3V02/F+PXI87b+hfdYl/sMeBcqWK6dmshCMlYoqlCkjnSrLuHwOATwVNFYQl604W\nBRHQ0SdtoSXrBdwOCwa6HTg3EUe+WAZnpssj4Hkevzo1g+dfOotCqYJbd/Vi/74tTV2j2j7yNEZn\nUpL20CXiGQvJv38MABaTAS67WdHVuiLxHBgG6HJJEZDnb1CoOIgm0Ax5iZ3DPpQrPN4Zjcs9FMXI\nFcp45p/P4Pv/8jZYFvg/PrwNv//BrU3fsAz0CIldtI+sVmNh+TOsBQE3h7lkAdWqMjOLo4k8upyc\nJGe1/W4rGNCStVZQQF6ivo9Mx58ALDhbfLpxtvimbT0tvUZ/oNYZiBK71Ks+Q1ZAQPZ7rKhUecyl\nlLdMWypXEE8VJEnoAmo5Gl6XpV47m6gbrckusXmDC1aLEScv6Pv4U5XncejoGH7yygiqVR4f2jOI\nj9y6qa27frPJgD6/DWPhFKpVHiyrz2uqZmOhFJw2EzwO+TN5612f4nlJjha1IprIg4c0CV2CgNuK\ns+NxqoanAfSvt4SBZbFtyItoIo+QTvdlEukC/ubAb/Gjly/AYTPhCw9dgwfet3ldS3CD3U4US1XM\nzFFil9pk8yVEE3kMBB2KuEGtJzIpcFYoZUKXIOCxgoc6umCR1VFAXoaejz+duDCL//sHb+D0pRh2\nbfbhf/z+jYsKfbRrkPaRAQCVqvqOfo2HlbNcDSyeIStNVMIjT4JGTWvlXQ/SGgrIy9BjO8ZWzha3\nox6QdbyPfOJCFH/0//wSpy/OyT2UlowqaP8YaAQ7Jc4IhaDY6bKZC9UzrSmxS/UoIC/D67RgY8CO\nd8fjKJYqcg+n49o5W9yq/qADDPQdkH97LopyhceB/zyPqopqDzdqWCvjyFqX0wKGUWa1LmEZXeol\na4ACshZQQF7BzmEfSuUq3hnT7vGnhX2LR0Mp3LqrF1/71PX12ayYOLMRPb75xC4VBSMxjUzVGmxM\nRNJ440xI5tE0byyUhtnEottrk3soAACjgUWXk8OsEgNyPAezkYXLLl3yW5ACsmZQQF5BvfuTRpet\n13u2uB2DPU7kChVdFjEolCqYiGQQ9FphYBn84+ERVZQSLZWrmJ7N1I6uKSg73u/mEE8VUCor6xpG\n43n4PVZJk98cVhM4s4HaMGoABeQVbNnohsVs0OQ+shhni9vR6Pykv2Xr0ZnaysA1V/jx/ms3IBLP\n4/DxKbmHtaapaAaVKq+Y/WOB38OBBzCbVM4sOZMvIVso15POpEJtGLWDAvIKjAYW2wa9CMVyCMe0\ncVRntb7FUqgHZB3uIwvL1cN9LvzuzUOwmAx48VeXUFB4joJw89SvkP1jQWBBG0aliMqQ0CUIeqwo\nlqpIZkuSvzcRDwXkVTSyrdWVFbucTpwtbtWAjmfII1MJALW+2267GXfe0I9EuohfvDUh88hWNz6f\nYT2owBkyoKzErnrbRYlnyMCCxC4dbgdpCQXkVewY1kb3p5MjnTlb3CobZ0TQa8XoTEp3S2sj00m4\nbKZ6t6K7bxyAnTPiX4+MIpNX7qxmNJwCyzCK6w/uV+IMef7mQMozyAI6+qQNFJBX4Xdb0euz4Z2x\nGEplZS8tLqdUruLAf57D3/yvzpwtbsdgtxOZfFmRGbKdEk8XMJcsYLjPXU/2sXFGfHDPILKFMv79\n6JjMI1xelecxHk6j12eD2WSQeziLNKp1KedzVJ8hyxGQvZRprQUUkNewc9iHYqmKs+MJuYfSktBc\nFl/6n6/g0BudO1vcDj1W7BL2jzf1uRY9fsd1G+FxmPEfb44jni7IMbRVRWI5FIoVxe0fA4DbYYbR\nwCpqhiycQZY6qQto3ARQprW6UUBegxqrdkXjOTz+/Fs4P5Ho6NnidgjjuKSjxK6FCV0LmU0GfPjW\nTSiWq/inX12SYWSrGxNKZgaV8dlZiGUY+NxcfZlYCaLxPBxWE6wW6Xv2+FxcrVgKBWRVo4C8hiv7\n3TCbWNUE5FyhjG//+ARS2RL+20d2dPxscav0ePRpZCoBBsCmHtdlf3brzl4EvVa88tspxc1uhApd\ngwqcIQO15Kl0roRcoSz3UFDleUQTOcnaLi5lNLDwuTgKyCpHAXkNJqMBVw94MT2bVWTt3IWqVR7P\n/NMZTEYy+MB1G/Dh2zbLPaTLOKwm+FycbhK7qlUeF2dS6PHZYOMuvzEyGljcf9swKlUePz08IsMI\nV9Y48qS8GTLQWBpWQj5CIl1EucLL2g4y4LEini7qotyvVlFAbsLOetUuZR9/+vEvL+C356PYNuTF\n7+3bIvdwVjTU40QqW0I8XZR7KB03NZtBoVi5bLl6oeuvDmIg6MDR0yFMzC8TK8F4KA2fywKH1ST3\nUJblV1AbRjkTugQBBR4FI62hgNyEnZuVv4/82slp/NvRMXR32fBH9+2AgVXuP+1AfR85KfNIOq+x\nf+xe8WdYhsH979sMHsBPXlHGLDmRLiCRKaJfgfvHAiW1YYzU2y7Ks2QNUJMJLVDut7aCBD1WdHut\nODMaU2T94XMTcfzw39+BzWLEox/bBTunzBmNQE8Vu+oBuXflGTIA7BzuwpX9Hvz2fBTnJuRvaFJP\n6FLo/jGw8OiT/AFISC4LyLzH6lz8AAAgAElEQVRkDVBxEDWjgNykncM+FIoVnJtQ1vGnaDyH7/zk\nJKpV4I8+ugM9XcroyLMaIdN6LKSc5dlOGZlKwmxksTG4emENhmHwsffV9vx//MsR2ffXGy0XaYbc\njMaSNc2QSfsoIDdJid2fcoUynpzPqN5/5xZsl6H6VjvcdjO8TovmM63zxTImo2kM9jib2kK4YqMb\n11zhx9nxOE5dlDdfQbhZUvIM2WE1wWI2KCLZMhrPgWGALpd8ATlIxUFUjwJyk64e8MBkVM7xJyGj\nemI+o/oD122Ue0gtGex2Ipaq7VNqVS2T/PLzx6u5/7ZhMAB+/PIFWftGj4VSsHNG+GQMMGthGAYB\nN4dIIi/7ikIkkUeX0yJpbfil7JwJNotRccfnSPMoIDfJbDLgqn4PJiIZxFLyV1VSS0b1SoSZl5b3\nkZtJ6FpqY9CB927vxlg4jV+/E+7U0FaVK5QRjuXQH3TIXtltLX63FYViBemcfPXAS+Uq4qmCrBnW\ngoDHimgiL+vNHGkfBeQWKKVql5oyqlcyNF8kQ8vL1s0mdC11395hGFgGP3llRJYkwolIGjyUvX8s\nELKa5azYNZvMgwdkPYMsCHitKJWrSOjgSKEWqe+bXEZKOP6ktozqldRrWmt5hjydhNtuRpfL0tLz\ngh4rbrumD+FYDq+enO7Q6Famhv1jQb0vsowBOaqAI08C6vqkbhSQW9DttcLv5nDm0pwsMxc1ZlSv\nxOMww2UzaTYgx1IFxFIFDPe52lr2vffmIZiNLF589aLklZfUkGEtaGRayxeAlFAURECZ1upGAbkF\nDMNg52YfcoVKfTlSKmrNqF4JwzAY6HFiNpmXdf+vU0amasfjWknoWsjjsODOG/oRTxfxi2MTYg5t\nTWOhNIwGVhU3fH4FtGGMKOAMsiBIAVnVKCC3aOcm6ZetF2ZU367CjOqVDGm4FWO7+8cL3f3eAdgs\nRvzrkVFk89I0UChXqpiMprExYJc1Y7hZypohK2HJmtowqpnyf+MUZuugF0YDI2lAXpRRfYf6MqpX\nouWKXSNTSTAAhtYRkO2cCffcNIBMvox/f2NMvMGtYno2i3KFV8X+MQBYLUY4rCZZZ8jReB5mIwuX\n3SzbGARdLgsMLEMzZJWigNwii9mAK/s9GAulkZCgqfzSjGo1zFqapdWAXK3yuDSTQp/fvu7euPuu\n74fbYcZ/vDkuyZltNe0fC/xuDrOJnGxHfaKJHHxuThFHxAys0IZR/uplpHXa+XaX0I75ZetOV1PS\nSkb1SnxuDnbOqLkl68loBoVSBZva3D9eyGIy4MM3D6FQquCff3Vp/YNbQz3DWsFNJZbye6woV3hZ\njvpk8yVk8mVFJHQJAh4OyUwR+aL8faJJayggt0GK409ayqheCcMwGOxxIhzLSbZHKoX1JnQttXd3\nHwIeDi//ZrLjS5Hj4RQYYM3a20oScMt31EeYiSohoUsg3BwoocY3aQ0F5Db0+Wzocllw+uIcqlXx\nl8m0llG9GmHZekxDs2QxEroWMhpYfHTvMCpVHj979aIor7kcnucxFkoj2GUDZ17fUruUhExrOWpa\nC++phDPIgoCXErvUigJyGxiGwc5hHzL5MkamxT3+VOW1mVG9kkENZlqPTCdhNrHYEBBvlnnjtm5s\nDDhw5NQMJiKd6ZIVTeSRLZQxqJKELoEwQ5ajOEh9hqykJWs3HX1SKwrIbarvI4u8bK3VjOqVaC0g\n5wplTEUyGOpxiVrSlGUYPPC+YfAA/vGVEdFed6FGhS717B8DtVwEQJ4lWqEXs3D8SgmoOIh6UUBu\n07YhLwysuMefXjs5jX97XZsZ1SsJeKywWgyaybS+NJMCD/H2jxfatdmHKza68ZtzUVyYFL8vdz3D\nOqiuGXL9LLIcS9ZKnCHTWWTVauob/+zZs9i3bx+ef/55AMD09DQeeeQR7N+/H48++iiKxVp244sv\nvogHHngAH//4x/GjH/2oc6NWAKvFiC0b3bg0nUIyu/7szvMTCU1nVK+EZRgMBJ2Ymc1qIiu0ntAl\n0v7xQgzD4GPv2wygtpIidsvB8XBthtyvshmyyWiAx2GW5ahPJJ6Dw2pa9/E2Mdm4+bPZlNSlOmsG\n5Gw2i8ceewx79uypP/bkk09i//79eOGFFzA4OIiDBw8im83iqaeewj/8wz/gueeeww9/+EPE4/GO\nDl5uO4Z94AGcXufxp2gih//5kxOazqhezWCPEzwaAUHNGi0XxQ/IAHBlvwe7Nvvwzlgcpy+Je+xu\nNJSC22GGWwEFLlrl91gxl8pLWmO+yvOIJvKKWq4WBDzzZ7M7kHRKOmfNgGw2m/HMM88gGAzWHzt6\n9CjuuOMOAMDtt9+OI0eO4Pjx49i5cyecTic4jsN1112HY8eOdW7kCiBGO8ZcoYwnD+ojo3olWun8\nxPM8RqaT8DjM6HJ17kv6/tuGAQA//uWIaMUwUtkiYqlCPetdbQJuDjwPzEnYqzyRLqJcqSpquVoQ\nmD+brYTe7aR5a66zGI1GGI2LfyyXy8Fsrt1F+3w+RCIRRKNRdHU1gklXVxcikciqr+312mA0GtoZ\n94oCAem+UPx+B7pcHM5cisHnc4BlW6vUU63yePwf3sBEJIMP3jyEB+/aKvoYpbwe7bp2K4B/OoOZ\neL7j4+3k60diOSTSRezZ2dvR9wkEnLjtmg145beTODedwq27N7T9OoLJs2EAwFVDXar4zCw10OfG\nkdMhlHmm7fG3+rxwqrZVNdDrUtw1G+xz4423wyhBuuuhZVJdi3VvfKy0j9XM/lYsll3v2y8SCDgR\niUg7y9o25MWrJ6bx61NT2NTivuGPXj6Po6dnsHXQi/tuGRJ97HJcj3aYwcNiMuDs6FxHx9vp6/Hr\nd2pBbYPP1vHrfs97+/HaiSn88J/P4IoeR8sZ3UuvxcmztZvngNOiis/MUjZT7e9/fmwOfd7WVyfa\n+WycH62tjNnNBsVdM7u5NtE5d2kWPe7W+nED6vnukILY12K14N5WGq/NZkM+X0sYCIVCCAaDCAaD\niEaj9Z8Jh8OLlrm1qt1l64UZ1f/nR/WRUb0SlmXQ3+3AVDQree9fMYldEGQ13V4b9u7qxcxcFq+d\nnFn36wkZ1v0qO4MskOPsrRLPIAuClGmtSm1FgZtvvhmHDh0CALz00kvYu3cvdu/ejZMnTyKZTCKT\nyeDYsWO4/vrrRR2sEm0f8oJlWjv+pNeM6tUMdjtR5XmMd6johRRGphJgGGCoV5rlrXtv2QSTkcXP\nXr2IUnl9NzJj4TQ4s0GRwaUZQqUsKYuDCC0flVSlS0BnkdVpzSXrU6dO4Zvf/CYmJydhNBpx6NAh\n/NVf/RW+8pWv4MCBA+jr68N9990Hk8mEL3zhC/j0pz8NhmHw2c9+Fk6n9vcgbJwJmze4cH4ygXSu\nBId19eCq94zqldRLaM6ksLnPLfNoWlepVnEplMIGv12yspNepwX73rMR/3Z0DP95bBJ33TjQ1usU\nShVMz2awZYMbrAI6FrXD66y1HZTyLHIkkQcDwNfBBL52CdeDjj6py5rfHDt27MBzzz132ePPPvvs\nZY/dfffduPvuu8UZmYrsGPbh3EQCZy7N4cat3Sv+3MKM6od/50pdZlSvRO0VuyYjGRRL1Y4dd1rJ\nPTcN4uXfTuFfjozitt19bZ2HnYikwfPqO3+8kIFl4XVaJK3WFYnn0OWyKHK7iWUZ+D1WmiGrjPI+\nSSq0S9hHvrDysrXealS3qs9vg8nIYnRGnUvWjfPH0s7uHVYT7nnvANK5Eg69MdbWa4zXS2aqc/9Y\nEPBYkcgUJclDKJWriKcK8Cuoy9NSAQ+HdK6kqU5qWkcBWQT93Q64bCacvDi34rlQoUb11kF91Khu\nlYFlsTHgwEQkjVJZuuIOYpEyoWupO6/vh8tuxqE3x9uqGtcomaneGTKwsIRm52fJc8k8eChz/1gQ\nkLELFmkPBWQRsAyDHcM+JDPF+mxjIcqobs5gjxOVKo+paEbuobRsZDoJi9mAPr/0fYQtZgPuvXkI\nhWIF//Kr0ZafPxZOw8AyonankoOUbRiFpWAlJ8HVM61jFJDVgiKDSHYM1/aDT11cvGxNGdXNG1Lp\nPnKuUMZ0NINNPc6Wi8OI5X3X9MHv5vBfv5loKSBVqzwmwmn0+e2qv1EU2jBKkcgUmZ+FBxS9ZD2f\naU0zZNVQ92+gguzY5APDLN5Hpozq1giZ1moroXlxOgkewCaJE7oWMhpY3Ld3E8oVHi++eqnp583M\nZVEsV1W/fwzQDHmpxtEn9WVaF0sVnB3Xdi+E5VBAFonDasJwrwvnJ5PI5svIF8t48uBJXdeoblWf\n3w4Dy+CSygJyY/9Y3uNaN23rwQa/Ha+dmsZkk8v+Wtk/BhozZCkyrZV8BlkQmB9bROSKiFL46eGL\n+Mv/9xhOrJIoq0UUkEW0Y9iHKs/j9KU5/P2LZzARSVNGdQtMRhYbAnaMh9OSdu1Zr053eGoWyzK4\n/33D4Hngp6+MNPWcsbA2MqwBwGU3w2xkJVmijSTyMBlZRXfG4sxGuGzqa8NYqVZx5HSt+twvfzsp\n82ikRQFZREIZzecOvUsZ1W0a6nGiXKliZlYdd/VChyev0wKvs/WawWK75go/Nm9w4a2zEVycTq75\n8/WSmRqYITMMA5+bw6wEWdbReA5+NwdG4YVUAh4rZpN5VKrqucF9ezSGRKZ2WuDEhdn6/9cDCsgi\nGupxwmE1IZ0rUUZ1m4R9ZLUsW88m80hmirLPjgUMw+CB2zYDAA6+fGHVn+V5HmOhNAIeDjZOmupi\nneZ3W5HJlzt69jabLyOTLyt6/1gQ8FpRqfKYS6qnDePrp0MAgBu3BlGp8vjVqWmZRyQdihYiYlkG\n793WDZfNRBnVbRpQWaa1UparF7p60Isdm7rw9mgMZy7NrfhzsVQB6VwJAyqu0LVUo6Z155athdcW\nzj0rmRxNN9ajUKrgrbMR+N0cHv6dq2A0sHjl+HRT3QO1gAKyyPbv24K/+uwtlFHdpv6AAyzDqC8g\ny1AQZDUPvK82S/7xLy+s+GU2JlToCqp//1jQCECdW7ZWQ4a1IOhVV0D+7bkoCsUKbtreDYfVhPdc\nFUBoLotzEwm5hyYJCsgiYxiGlqnXwWwyoM9vw3gojWpV+XfFI9NJsAyDoR5lBeTBHieuvzqIi9Mp\nHJvvdbzUWHg+w1pLM2R352fIQrBXctlMQUBlbRhfn0/mumlbDwBg765eAMDhE1OyjUlKFDmI4gx2\nO1EoVTAzp+zErnKlitGZFDYE7LDMN4RXko/u3QSWYfCTV0aWTeqpz5A1FJDr5SI7OEMWgn1AwUee\nBGo6i5zKFnHq4hwGu531indXD3rhd3N4850wcgXt1+SmgEwURy37yJORDEpl6Ts8NavXZ8etu3ow\nPZvFr07NXPbnY6EUnDYTPA7lHt1plbCH3MmjT2qaIbsdZpiMrCqWrN98J4xKlcdN2xsd81iGwa27\nelEsVfHG2yEZRycNCshEceolNBWeaT0yVdvXUtr+8UIfvmUTjAYWL756cVHTjnSuhGgij4GgQ/FH\nd1ph50ywWowdbTARTeRg54yqyExnGQZ+N4eICupZHzk9A4bBZS1sb93ZCwbA4RPaz7amgEwUpz/o\nAAM1BGTlZVgv1eXicMd7NmA2WcDLv2kUWbg4fzOhpeVqQcDNIZrIdSQzt8rziMTzqkjoEgQ8VmQL\nZWTyJbmHsqJwPIcLk0lsHfRedp6/y8Vhx7API1NJTETU2Z61WRSQieJwZiN6fDaMhVMrtrNUgpHp\nJDizAb0+ZXdJ+uBNg+DMBvzTry7V9+FGJmsBuV8DFbqW8nusKJaqSGbFD0CJdBHlSrVeN1sNgh7l\nZ1ofXZLMtVQ9ueu4tmfJFJCJIg32OJErVBT7JZLNlzA9m8WmXpdsHZ6a5bSZcfd7B5DOlfAfb44D\naATkQQ3OkDuZaV1P6FLBGWRBQOFtGHmex5HTIZiMLN5zVWDZn7lmix9OmwlHTs+osl96syggE0VS\neueni9O1cSl5uXqhO6/vh9Nmwr+/MYZUtoiRyQTMJhbdXu2dl/d3sMmEms4gCwIKnyGPhlKYmcvi\nmiv8sFqW35c3Gljs2d6DdK6E356PSjxC6VBAJoqk9ICshoSuhawWI353zxDyxQp+9upFjIdStSIs\nCp/dt6OTbRiFIK/kLk9LBbzKPvp05FQte3rP9uWXqwV7d/cBAA4f1+6ZZArIRJGEZCOlHn1SQ0LX\nUu+/dgN8Lgv+89gkKlVekwldQGM5uRMBKFJfslbPDNlfvx7KmyFXqzzeeDsEO2fEjuHVW9Ru8Nux\nuc+F0xfnJGkgIgcKyESRbJwRQa8VozMpxdWxFTo8+VwWuB3yd3hqlsnI4iO3Dtf/W4sJXUDjfHAn\nZsiReB4MAJ+K9pAtJgPcDrMiA7LQ2enGrd1NVTjcu7sPPIDXTmozuYsCMlGswW4nMvkyZpPKuhuO\nJvJIZUvY1OeWeygtu3lHD3p9tX1jLSZ0AYDFbIDLZurIHnI0kYPXZVFdedzgfBtGpfUZF/oeLywG\nspobrg7CYjLg8IlpRZ/AaJe6PlVEVwYVWiBEqQ0lmsGyDP7ww9vxyQ9urRdg0SL/fAASsx56uVJF\nLFlQRYWupQIeK3geirq5XdjZ6YoNzd3cWi1G3LA1iNlkHm9finV4hNKjgEwUa1Ch+8hq3D9eaKDb\niY/fcaWmKnQt5XdzqFR5xFLi9QGeTeTBQx01rJdSYqb1ws5OrXwWb9s1n9ylwYYTFJCJYjVmyMqq\nzjMynQDLMPXxEeUJdCDTWo0JXYKgAptMLO3s1KzNG1zo9dlw7GwE6Zxyq4+1gwIyUSyH1QSfi8Po\nTFIxiV21Dk9pbAzaYTEpr8MTqWkUBxEvAAnBTE1nkAX1GbJCioMs19mpWQzDYO+uPpQrfH0PWiso\nIBNFG+xxIpktIZ4uyj0UAMB4OI1ypYphFSZ06YmwzyvmEm10/rXUdAZZICyzK2XJernOTq24eUcP\nDCyDw8enFXOzLgYKyETRlJbYpeaELj0RgqaoM+SEetouLuWym2E2KacN4+unQ2BweWenZrnsZuy+\nwo+JSBqXFPLdIAYKyETRlJbYpfaELr3wuTgwaMxqxRCJ52AysnCrsH80wzAIeKwIxzvTBasV4XgO\n5ycT2Dp0eWenVty2e77hhIbaMlJAJoqmuBnydBJWS60bFVEuo4GF12Wpz2rFEI3n4HdzYFWanR5w\nW5EvVmRPhFqrs1Ozdmzyweu04OiZGRRKFTGGJjsKyETR3HYzPA6zImbImXwJobksNvU6VfulrCd+\ntxXxVEGU7kDZfBmZfFmVy9WCoAJqWjfT2alZLMvglp09yBUq+PU7YZFGKC8KyETxhnpciKUKSGTk\nTey6SMvVqhJwc+ABzIlQDKPedlGFCV2CehvGeFa2MTTT2akVt9bPJGtj2ZoCMlG8gfmay3IvWzcS\nuijDWg2Erk8REc4iC7NKNc+QG5nW8s2QXz/dXGenZgU9Vlw94MHZ8ThCc/LdaIiFAjJRvPo+sszL\n1iPTNENWEzH7ImtphixXpnW1yuPomeY6O7Wi3pZRA7NkCshE8YZ6agFwTMYZMs/zGJlKwu/m4LKr\nL8tWjwKizpCFgKzeGbLfXcs8l6s4iNDZ6YYmOzs16z1XBmC1GPHaqWlUqspqntEqCshE8TwOM1w2\nk6wz5Eg8h3SuRLNjFRFmyGL0zo2q+AyywGQ0wOO0iHKD0g6hqtaeNouBrMRsMmDP9m4k0kWcvDAn\n6mtLjQIyUTyGYTDQ40Q0kZftyAYVBFEfj8MCA8uIsmcaiedg54ywcetPRJJT0GNFLClO5nkr2uns\n1Iq9Gmk4QQGZqILcBUIaBUEooUstWJaBz82tu8EEz/OIJvL1JDE1C3is4CFu041mHD/fXmenZg32\nODHQ7cDx87OIp8Xr8CU1CshEFYTevXLtI49MJ2FgmXrGN1GHgJtDKltCvlhu+zUSmSJK5SoCbvUm\ndAnkyrQ+ckqcYiCr2burD1Wex69OqbfhBAVkogpyzpBL5SrGQilsDDpgpg5PquKvt2FsPwBpIaFL\nEPBKn2m9ns5Orbhpey1Z7PAJ9TacoIBMVMHn5mDnjLIUkq91eOIpoUuFxDj6JDxXK0vWgLQBeb2d\nnZpl50y4/qoAQnNZnJtIdPS9OoUCMlEFhmEw2ONEOJZDNt/+8mM7RqZqv9yU0KU+Yhx9Ep6rjSVr\n6QPyejs7tWLvrvmGE8fVmdxFAZmohrBsPR6WdpZMBUHUSzimtJ4ZspaWrJ1WEzizQbKALFZnp2Zd\nNehFwMPhzXfDyBWkvXEXAwVkohpCxS6pl61HppKwWYzo7qIOT2rT6IvcfgCKxvNgAHS51D9DFtow\nRuJ5SfZZxers1CyWYXDrrj4US1UcfTskyXuKiQIyUQ05ErvSuRLCsRw29bmow5MKOa0mWEyGdSV1\nRRM5eJwWmIza+LoMeKwolCpIZjt7pp/nebx+RpzOTq24dWcvGEady9ba+IQRXQh4rbBaDJI2maCC\nIOrGMAz882eR25kRlitVzCULmliuFgSFfeQOl9AcDaUwPSteZ6dmeZ0W7Bz24eJ0ChPhtGTvKwYK\nyEQ1WIbBQNCJmdksCkVpGpLXE7po/1i1/G4OuUIFmTaSAWeTefDQRkKXoHEWubMBWejs1Ons6uUI\nyV2vqKxyFwVkoiqDPU7wAMYkSuwSEro2UUBWrcZZ5NYDkJYSugRSZFov7Oy0c9jXsfdZye4r/HDa\nTDhyakbyMqHrQQGZqEq9FaMEy9Y8z+PiVBIBDweXjTo8qVVgHWeRG2eQNTRDni8OEu5gQO5UZ6dm\nGQ0sbt7Rg0y+jN+ci0j+/u2igExURcrErnAsh0y+TPWrVc6/jrPIwnPU3OVpKZ+LA8N0dob8eoc6\nO7Wi0XBCPX2SKSATVenpssFsYiWZIVNClzasp1qXUPNZS0vWRgOLLifXsYBcKFXw6w52dmpWn9+O\nKza4cebinOTNNNrVVurb0aNH8eijj2LLli0AgCuvvBJ/8Ad/gC996UuoVCoIBAL41re+BbOZlvmI\nuFi2ltg1MpVEsVTpaG3pRocnCshqtp5qXdF4DkYDC7dDW99lQa8Vb4/GOvI7JHR2uvP6jR3p7NSK\nvbt6cX4ygVdPTOO+vcOyjqUZbc+Qb7zxRjz33HN47rnn8N//+3/Hk08+if379+OFF17A4OAgDh48\nKOY4Cakb7HGiyvOYiGQ6+j4j0wnq8KQBVosRds7Y3h5yIg+/m9PcGfR6pvU6zmevRIrOTs26YWsQ\nFrMBr52cRrWq/IYToi1ZHz16FHfccQcA4Pbbb8eRI0fEemlCFpFiH7lUrmAslMZAtwMmI3V4Uju/\nx4poIo9qC2eRc4Uy0rmSpparBZ3KtBY6Ow10Ozra2alZnNmIG68OYjZZwJnRObmHs6a2A/L58+fx\nmc98Br/3e7+H1157Dblcrr5E7fP5EImoJ7ONqEsj0zrZsfcYC6VRqfIY7qWELi0IuDmUK1UkM8Wm\nnyMEKy1lWAsCHSoOInR22rNd/tmxYO/u+eSu48pP7mprD3loaAif+9zncM8992B8fByf/OQnUak0\nCjU0WxHH67XBKPLsIxBwivp6aqfF69HVZYfZyGJyNtvy36/Znz/ydhgAsPvqoCavIaDNz8ZK+nvd\n+PW7EZTBrvj3Xvr4+ZlalaehPo/mrtWV80VS0sVK09ejGW+djYJhgHtuHYZPIZnpfr8D/S+9i9+c\ni8Jis8Blbz0fQKp//7YCcnd3Nz74wQ8CAAYGBuD3+3Hy5Enk83lwHIdQKIRgMLjm68Ri2XbefkWB\ngBORiPT9cpVKy9djQ8CBS1NJTM8kmj7n2Mr1ODF/djHgMGvyGmr5s7Ecu7n2GTk3Ogu/w3TZny93\nPS6M1ZY4bSZGc9fKOD9pGptKLPt3a+fzEY7n8PalOWwb8qJaLCvqmt28vQcH/vM8/vmX53HnDf0t\nPVfs35XVgntbS9Yvvvgivv/97wMAIpEIZmdncf/99+PQoUMAgJdeegl79+5t56UJacpgjxOVKo/J\nDiV2jUwlYOeMCHqVcZdP1qfRhrH5Jdp6URCFzPTE5LCaYLMYRS0OInVnp1bs2dEDA8vglRNTknS5\naldbM+QPfOAD+OIXv4hf/OIXKJVK+PrXv46tW7fiy1/+Mg4cOIC+vj7cd999Yo+VkLrB+czn0VCq\nvqcslmS2iEg8jx3DXbIf2yDiaCerWDgmpcWkLqD295qazaDK8+vOIpers1OzXDYzrtnix1vvRnBx\nOqXYo4xtBWSHw4Gnn376ssefffbZdQ+IkGYM9dR+oUZnUsBucV/7IhUE0ZxGcZDmZ4SReA52zggb\nJ12nIikFPBxGQykk0kV4nZZ1vZbQ2emGq4OSdnZqxd5dfXjr3QgOn5hSbECmSl1Elfr8dhhYpiNH\nnxoFQSjDWitMRgPcDnPTfZF5np8/g6zN2THQqGktxtEnOTs7NWvHpi54nRYcPROSrFtcqyggE1Uy\nGVlsCNgxHk6jUhW3m4vQ4Umpd9GkPQG3FXPJQlOfl0SmiFK5Wl/q1iKxziLL3dmpWSzL4JadvcgX\nK/j1u2G5h7MsCshEtQa7nSiVq5iOipetX53v8BT0WuGwXp6NS9TL7+FQ5XnMJQtr/myjy5OGZ8gi\nBWS5Ozu14tb5PsmHjyuzT7Kyrx4hqxjqEb9iV2gui2yhTLNjDapnWjexbF1P6HJrd4Yc9IjThlEJ\nnZ2aFfRYsXXQi7MTCczMiXvsVgwUkIlqDXSgNzJ1eNKuQAuJXcKsUasZ1gDQ5bKAZZh1zZCV0tmp\nFXt3z8+STyhvlkwBmahWf8ABlmFwScQZcmP/WB1fLqR5QqZ1M0ef9LBkbWBZ+NyWeovJdgidnd67\nrVs1RwTfc2UAds6I107OoFwRN/9kvSggE9Uymwzo89swHkqL1sllZCoJo4FBf5A6PGmNEFyb6Y0b\nTeTAAPC5tLtkDdSWcGsMp54AABAVSURBVJOZIvLFclvPr3d2UlDt6rWYjAbctK0HyUwRJy/Myj2c\nRSggE1Ub7HaiUKogJEIZ1mKpgolwGgPdTpiM9KuhNcISbTNtGCPxHDxOi+Y/B8KSfDutKRd2dtqg\ngM5OrWgsWyur4YS2P21E84R95Esi7CM3OjzR/rEWGVgWXS5LPWFrJeVKFXOpgqYTugTrybT+tQI7\nOzVroNuJwW4nTlyYRTy9dta9VCggE1Wr90YWISCPTCUA0PljLfO7OSTSRRRLKxeGmE3mwfPaTugS\nBNaRaX3kdAgMgBu3Kj+7ejl7d/eiyvN47aRyZskUkImqDXQ7wAAYEyGxiwqCaJ+wjzybXHmJVg8J\nXYJ2Z8jheA7nJxPYOuRdd9lNudy0rRsmI4tXT0wrpuEEBWSiapzZiB6fDaOhFKrr/KUamUrCYTXp\nYmakV8Iy9GqZxcKStl9XS9at7SErubNTs2ycCddfFUAolsPZ8bjcwwFAAZlowGC3E7lCZV3nKZOZ\nIqKJPIb7XKo5vkFa10ymtR7OIAtsnBEOq6mlJWuld3Zqxd5dfQCAV44rY9maAjJRvUERCoRQQRB9\nCDRRrUtYstZDQAZqXZ9mE7mmjw6OhdKYns3imiv8iu3s1KyrBjwIeqx4690wsvn2jn6JiQIyUb16\nYtc69pFHpimhSw98TVTriiZyMBpYuB1mqYYlq4DHinKFbzrb+IiwXK2CUplrYRgGt+7qRbFcxdG3\nQ3IPhwIyUb+B7loRjzERZsibKCBrmtthhtHArlqtKxLPw+/mwOpk66KeaR1be9laLZ2dWnHLzl4w\njDIaTlBAJqpn40wIeqy4NJNqK1uyyvO4OJ1Ed5cNdo46PGkZyzDwu7kVZ8i5QhnpXAl+DbddXKqV\nTGs1dXZqltdpwc5hHy7NpDAeTss6Fm1cUaJ7gz1OZPLlVY+zrGRmNotcoUL7xzrh93DI5MvIFS7f\nMxT2loW9Zj2oB+QmSoqqqbNTK27bXUvuknuWTAGZaEIjsav1O9x6QhctV+uCEGyXmxHqKcNaEGxy\nyVqNnZ2atWuzDy67GUdOz6BUXrloTKdRQCaa0EjsSrb8XCoIoi/CcvRymdbCUrYeziALvE4LDCyz\n5llkNXZ2apbRwOLmHT3I5Ms4djYq2zgoIBNNWN8MOQGjgaUOTzpRP/q07AxZX0eeAIBla/vqa+0h\nv366loWsps5Ordi7S/4+yRSQiSY4rCb4XBxGZ5ItJXYVShVMhDMY7HFoJkmFrE6YIS+XaS3sowZ0\nlNQFAAGvFelcadl9daDW2enkyKwqOzs1q9dnxxUb3ThzKbbqsbhOom8gohmDPU4ksyXE08WmnzM6\nUyu5OdyrrT0xsjL//Ax5drkl60QeNosRNp1l26+Vaa3mzk6tEGbJr8rUcIICMtGMwfnzyK1U7KKE\nLv2xc0ZYLYbLsop5nkc0ntPVcrVgtUQ3QP2dnZp1w9VBWMwGvHpyuunKZWKigEw0Y7CnFlRbqdhF\nCV36wzAMfC4rovH8ou2NZKaIYrmqqzPIgqB35TaMkfnOTlcPqrezU7M4sxHv3dqNuWQBZy7NSf7+\nFJCJZrRT0/riVAJOm0lXWbWktkdcKFWQypXqj0V0eAZZsFrXp9fP1JK5tL5cLdi7u7Zs/coJ6Zet\nKSATzXDbzfA4zE3PkBPpAmaTBQz3UocnvfHXM60bAahxBll/N2f+elvKy5fxXz89o4nOTs0a7nVh\ng9+O35yNIJltPh9FDBSQiaYM9bgQSxWQyKz9i0T7x/rVOIvcCED1M8g63EO2Woxw2UyILCkOoqXO\nTs1iGAZ7d/WiUuXx+qkZSd+bAjLRlHqjiSZmyY39Y8qw1pvlkpiEJWu9bl8EPFbMJvOoVKv1x7TU\n2akVe3b0wMAyOHxiuq36+O2igEw0pZV95HqHp15nR8dElGe5al3ReA4M9B2QK1UesWStDaMWOzs1\ny2kz49otfkxGMzg7FpPsfSkgE02pl9BcIyBXq7UOT70+m+7OnJJG0F1YACISz8PjtMBkNMg1LFnV\n2zDOXxMtdnZqxd75hhP/8caYZO+pv6tMNM3rtMBlM62Z2DU9m0G+SB2e9IozG+G0merL1OVKFXOp\nPAI6nR0DlxcHETo73bRNX8vVgu1DXehyWfDKbyYle0997NIT3WAYBgM9TpwamUM6V4LDuvzslxK6\niN9txVioVqktEsuB5/WZ0CUQsssj8TzyxTLeEjo7bdRnjgXLMnj4zqswOZeV7j0leydCJCIsW6+W\n2EUJXcTv5lCp8oinCgjNZeqP6VXQawNQW7J+83QI+fnOTqyOjwRes8WPT/3udsnejwIy0ZyhJhK7\nRqaSMBlZbAhos1A+WdvCxK6Z2dosSI9lMwVuhxlGA4tIPIeXj00A0G5nJ6WiJWuiOY3eyMsH5EKx\ngolIGps3uHWZrEJqFh59SuRqXY70HJBZhkHAw2FmNouJcFrTnZ2Uir6NiOb43BzsnHHFGfKlmSR4\nHpTQpXMLZ8ih+X1CPS9ZA7UbkkKpoovOTkpEAZloDsMwGOh2IhTLIZu/vL8rNZQgQGOGHI3nMDOb\ngdHAwKPx5glrEVYIGEb7nZ2UiAIy0SRhH3k8fPksmTKsCQB0uTgwqFXoCs1l4XNbdZ3ABDQC8q4r\n/Jrv7KREFJCJJq1WsWtkKgmX3QyfS9/Lk3pnMrLwOC2YjKSRzBR1fQZZcFW/BwaWwe/eOiz3UHSJ\nAjLRpJUSu2KpAmIp6vBEagJuDpk8JXQJBnuc+O4X34+bdvTKPRRdooBMNCngtYIzG3BpyQyZlqvJ\nQgsLgfh12HZxOSxLN6pyoYBMNIllGAx2OzEzm0WhWKk/PjKdAEABmdQszKoWkrwIkQsFZKJZgz1O\n8ADGw+n6YxenkmAAbKIjTwS18pkCWrImcqOATDRL2Ee+NFNbpq5UeVycSaHXb9dNs3WyusCCZWpa\nsiZyo4BMNKueaT2f2DUeSqFAHZ7IAsIM2W41wU5tOInMKCATzerpssFsYjE6U1uyfne01mic9o+J\nwOu0wGIyYGPAIfdQCKFa1kS7WJbBQNCJkakkSuUKzo5RQCaLsSyDP/nEbmzspa5fRH40QyaaNtjt\nRJXnMR7O4OxYDGYTdXgii13Z78EgbWMQBaCATDRN2Ec+Ox7H2EwSQ91OGFj62BNClIe+mYimCQH5\nl8enUOWB4T5amiSEKBMFZKJpvT4bjAa23l6P9o8JIUpFAZlomtHAoj/YyKClgEwIUSrRA/Ljjz+O\nBx98EA899BBOnDgh9ssT0jJh2brLZaGWcoQQxRL12NMbb7yB0dFRHDhwABcuXMBXv/pVHDhwQMy3\nIKRlg921GfKVA17q8EQIUSxRZ8hHjhzBvn37AACbN29GIpFAOp1e41mEdNa2oS6YTSz27KSWcoQQ\n5RJ1hhyNRrF9+/b6f3d1dSESicDhWL4Kjtdrg9FoEHMICAScor6e2tH1qF2DH//lvXIPQ3Hos7EY\nXY/F6Ho0SHUtOlqpi+f5Vf88FsuK+n6BgBORSGrtH9QJuh6L0fVooGuxGF2Pxeh6NIh9LVYL7qIu\nWQeDQUSj0fp/h8NhBAIBMd+CEEII0SRRA/Itt9yCQ4cOAQBOnz6NYDC44nI1IYQQQhpEXbK+7rrr\nsH37djz00ENgGAZf+9rXxHx5QgghRLNE30P+4he/KPZLEkIIIZpHlboIIYQQBaCATAghhCgABWRC\nCCFEASggE0IIIQpAAZkQQghRAArIhBBCiAJQQCaEEEIUgOHXKjhNCCGEkI6jGTIhhBCiABSQCSGE\nEAWggEwIIYQoAAVkQgghRAEoIBNCCCEKQAGZEEIIUQDNBOTHH38cDz74IB566CGcOHFC7uHI7okn\nnsCDDz6IBx54AC+99JLcw5FdPp/Hvn378JOf/ETuocjuxRdfxIc//GHcf//9ePnll+UejqwymQw+\n97nP4ZFHHsFDDz2Ew4cPyz0kWZw9exb79u3D888/DwCYnp7GI488gv379+PRRx9FsViUeYTSWe5a\nfOpTn8LDDz+MT33qU4hEIh17b00E5DfeeAOjo6M4cOAAvvGNb+Ab3/iG3EOS1euvv45z587hwIED\n+N73vofHH39c7iHJ7u/+7u/gdrvlHobsYrEYnnrqKbzwwgt4+umn8Ytf/ELuIcnqH//xH7Fp0yY8\n99xz+Pa3v63L745sNovHHnsMe/bsqT/25JNPYv/+/XjhhRcwODiIgwcPyjhC6Sx3Lf72b/8Wn/jE\nJ/D888/jzjvvxLPPPtux99dEQD5y5Aj27dsHANi8eTMSiQTS6bTMo5LPDTfcgG9/+9sAAJfLhVwu\nh0qlIvOo5HPhwgWcP38e73//++UeiuyOHDmCPXv2wOFwIBgM4rHHHpN7SLLyer2Ix+MAgGQyCa/X\nK/OIpGc2m/HMM88gGAzWHzt69CjuuOMOAMDtt9+OI0eOyDU8SS13Lb72ta/hrrvuArD489IJmgjI\n0Wh00S9SV1dXR5cVlM5gMMBmswEADh48iNtuuw0Gg0HmUcnnm9/8Jr7yla/IPQxFmJiYQD6fx2c+\n8xns379fN1+0K/nQhz6Eqakp3HnnnXj44Yfx5S9/We4hSc5oNILjuEWP5XI5mM1mAIDP59PN9+ly\n18Jms8FgMKBSqeCFF17Avffe27n379gry4iqgdb8/Oc/x8GDB/GDH/xA7qHI5qc//SmuueYa9Pf3\nyz0UxYjH4/jOd76DqakpfPKTn8R//dd/gWEYuYcli5/97Gfo6+vD97//fbzzzjv46le/SnkGS9D3\nKVCpVPClL30JN91006LlbLFpIiAHg0FEo9H6f4fDYQQCARlHJL/Dhw/j6aefxve+9z04nU65hyOb\nl19+GePj43j55ZcxMzMDs9mMnp4e3HzzzXIPTRY+nw/XXnstjEYjBgYGYLfbMTc3B5/PJ/fQZHHs\n2DHceuutAICrr74a4XAYlUpF1ytKQG1WmM/nwXEcQqHQoiVcPfqzP/szDA4O4nOf+1xH30cTS9a3\n3HILDh06BAA4ffo0gsEgHA6HzKOSTyqVwhNPPIHvfve78Pz/7d2hysJQGMbxR3AYLDZhC0MsXoPo\nTQhehAuuikWbDBaE3YQbWIxegcEieAuLw6QgiJi+pa+Oc3T/X1w5Dwt7OO85sE7HdByjttut9vu9\nsizTdDpVEAS1LWNJGo1GOp1Oer/fut1uejwetTw3/eP7vi6XiyQpz3O12+3al7EkDYfD8pt6PB41\nHo8NJzLncDjIcRzN5/PK1/qZvz3Fcazz+axGo6HVaqXBYGA6kjFpmipJEvV6vfJZFEVyXddgKvOS\nJJHneZpMJqajGLXb7cpbs7PZrLy8U0f3+13L5VJFUej1eikMw0pHkja6Xq+Kokh5nqvZbKrb7SqO\nYy0WCz2fT7muq81mI8dxTEet3H/voigKtVqtcpPX7/e1Xq8rWf9nChkAgG/2EyNrAAC+HYUMAIAF\nKGQAACxAIQMAYAEKGQAAC1DIAABYgEIGAMACFDIAABb4AF34fMpCpvyoAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f3a9c86e400>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "cg3-Y6mkN_v4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we can see the differences in a easier way, we will add weights to the different classes, based on how present they are in the dataset."
      ]
    },
    {
      "metadata": {
        "id": "vSNK4zzBN9S4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "total_cases = sum(classes)\n",
        "class_weight = [1 / (c/total_cases) for c in classes]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ahWzoz_g7JWE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Tokenize the dataset and use the word embeddings**\n",
        "\n",
        "This shows the set of different words ordered by frequency. *tokenizer.word_index*\n",
        "\n",
        "The text is tokenized and cleaned of stop-words as well as punctuation signs. Also the numbers are substituted by a token \"nmbr\"\n",
        "\n",
        "We crop the beggining of the examples because it is the date when they\n",
        "were written down.\n",
        "\n",
        "Finally, and after being tokenized, the different sentences are padded to match the maximum length.\n",
        "\n",
        "max_length == 7813 it is really a huge vector because we have to pad\n",
        "it afterwards, in order to get it into the CNN"
      ]
    },
    {
      "metadata": {
        "id": "IWBYdxobTYQJ",
        "colab_type": "code",
        "outputId": "b3c04735-856a-4ad9-92cc-6f7ea915193e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words=stopwords.words('english')\n",
        "\n",
        "MAX_WORDS = 5000\n",
        "\n",
        "# Defined from the dataset itself.\n",
        "DATE_LENGTH = 23"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xq9Z-kdItQpX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### CNN Input\n",
        "\n",
        "Here we take a maximum length of file by obtaining the accumulative density distribution of the training examples. This way we can see how many examples fall under certain threshold. Which will be fixed to 80% of the total examples. This length is 5000 words roughly."
      ]
    },
    {
      "metadata": {
        "id": "QZX0C6mHsSHg",
        "colab_type": "code",
        "outputId": "7b129672-aad0-4da1-c5d7-ca4b194e603e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "cell_type": "code",
      "source": [
        "cropped_date_text = [sentence[DATE_LENGTH:] for sentence in train_x]\n",
        "lenghts = [len(sentence[DATE_LENGTH:].split(\" \")) for sentence in cropped_date_text]\n",
        "plt.hist(lenghts, cumulative=True)\n",
        "\n",
        "# Set the maximum phrase size as 5000\n",
        "max_length = 5000"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeYAAAFKCAYAAADITfxaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMwAABiHMAAAYhDADAGCQ/wNpix5KIm+oDQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f3a980bd588>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "AjwTL9Vkhwle",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# We are using this function to clean the test set\n",
        "def tokenize_clean_text(text, tokenizer=None, max_length=None, \n",
        "                        max_words=MAX_WORDS, date_length=DATE_LENGTH):\n",
        "  \"\"\"\n",
        "  This function is in charge of tokenizing the text it is given. It also cleans\n",
        "  the text from stop-words, punctuation, and gives a special token to numbers.\n",
        "  \n",
        "  :param text: The texts to tokenize in a bidimensional python array.\n",
        "  \n",
        "  :returns: The tokenized and cleaned text in a bidimensional python array.\n",
        "            The tokenizer used to preprocess the text.\n",
        "            The maximum length used for padding.\n",
        "  \"\"\"  \n",
        "  # Consider to stemm or lemmatize the text \n",
        "  \n",
        "  cropped_date_text = [sentence[date_length:] for sentence in text]\n",
        "\n",
        "  if max_length == None:\n",
        "    # We get the maximum token length by splitting by spaces\n",
        "    max_length = max([len(sentence[date_length:].split(\" \")) for sentence in cropped_date_text])\n",
        "    \n",
        "  # We substitute the numbers by a token \"nmbr\" \n",
        "  cropped_date_numbers_text = [\" \".join([word if not word.isdigit() else \"nmbr\"\n",
        "                                for word in sentence.split()])\n",
        "                               for sentence in cropped_date_text]\n",
        "  \n",
        "  # Delete stopwords as well as every word less than 3 chars.\n",
        "  cropped_date_numbers_stopw_text = [\" \".join([word if not (word in stop_words or len(word) <= 3) else \"\"\n",
        "                                      for word in sentence.split()])\n",
        "                                     for sentence in cropped_date_numbers_text]\n",
        "  \n",
        "  if tokenizer is None:\n",
        "    tokenizer = Tokenizer(num_words=MAX_WORDS) # They use 5k words too\n",
        "    tokenizer.fit_on_texts(cropped_date_numbers_stopw_text)\n",
        "  # We tokenize the sentences\n",
        "  tokenized_text = tokenizer.texts_to_sequences(cropped_date_numbers_stopw_text)\n",
        "  \n",
        "  # Now we return the padded the sequences.\n",
        "  return pad_sequences(tokenized_text, max_length), tokenizer, max_length\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NdRl3K-k0DeN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_x_token, tokenizer, max_length = tokenize_clean_text(train_x, max_length=max_length)\n",
        "test_x_token, _, _ = tokenize_clean_text(test_x, tokenizer, max_length)\n",
        "assert len(train_x_token) == len(train_x)\n",
        "assert len(test_x_token) == len(test_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c1liHvDdIc7C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **TensorBoard**\n",
        "TensorBoard is a great tool for DL visualization. It shows the evolution of metrics during the training phase, as well as the weights, distributions, and even the graph of the neural net. \n",
        "\n",
        "We will be using tensorboardcolab in order to run a \n",
        "TensorBoard instance. This will initialize a ngrok machine and launch TensorBoard for us to see. \n",
        "\n",
        "TensorBoard will be accesible by the url "
      ]
    },
    {
      "metadata": {
        "id": "aN3qI7-RlOMh",
        "colab_type": "code",
        "outputId": "e497a564-6075-498b-d6c8-570034cf76f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# We install tensorboard colab in case we don't have it already.\n",
        "!pip install tensorboardcolab"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.19)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RqJWMm4pH-2f",
        "colab_type": "code",
        "outputId": "af40c77a-fb40-467c-aa20-c1c313f1f8ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorboardcolab as tb\n",
        "\n",
        "tbc=tb.TensorBoardColab()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "http://25c82e5b.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Xz02TQFG3dNE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#**Create a keras Embedding model**\n",
        "\n",
        "In this section we will create a Keras CNN model, compile, and train it.\n",
        "\n",
        "In this model we also generate the different embeddings for the words by using the Embedding Keras layer.  \n",
        "\n",
        "Some information about the architecture of the net is shown bellow. "
      ]
    },
    {
      "metadata": {
        "id": "W5FrX4FN3A2B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Embedding, Flatten, GlobalMaxPool1D, Dropout, Conv1D\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nVIsVEtM7fSq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Network parameters\n",
        "\n",
        "embedding_dim = 300\n",
        "filter_length = 128\n",
        "window_size = 3\n",
        "dropout = 0.1\n",
        "num_classes = len(train_y[0])\n",
        "fnn = [filter_length//2, num_classes]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WWo65gnF3nfx",
        "colab_type": "code",
        "outputId": "a08d3226-5da5-45b1-d178-eed948417d07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "cell_type": "code",
      "source": [
        "# Generate the sequential baseline model\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, embedding_dim, input_length=max_length))\n",
        "model.add(Dropout(dropout))\n",
        "model.add(Conv1D(filter_length, window_size, padding='valid', activation='relu', strides=1))\n",
        "model.add(GlobalMaxPool1D())\n",
        "model.add(Dense(filter_length//2))\n",
        "model.add(Dropout(dropout))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", \n",
        "              metrics=[\"categorical_accuracy\"])\n",
        "\n",
        "# Print a summary of it.\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 5000, 300)         1500000   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 5000, 300)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 4998, 128)         115328    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 13)                845       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 13)                0         \n",
            "=================================================================\n",
            "Total params: 1,624,429\n",
            "Trainable params: 1,624,429\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lTFqAwZM8F6z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define the callbacks\n",
        "callbacks = [\n",
        "    ReduceLROnPlateau(),\n",
        "    EarlyStopping(patience=4),\n",
        "    tb.TensorBoardColabCallback(tbc)\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aq68IX-Y807N",
        "colab_type": "code",
        "outputId": "95c30f94-e145-4a47-a71f-fdcbc6dba63a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        }
      },
      "cell_type": "code",
      "source": [
        "# Fit the model and extract its data\n",
        "history = model.fit(train_x_token, train_y, epochs=20, batch_size=32, \n",
        "                    class_weight=class_weight, callbacks=callbacks,\n",
        "                    validation_data=(test_x_token, test_y))\n",
        "\n",
        "# Set a name for the model based on the tweaked parameters\n",
        "name = \"embedding_{}_dropout_{}_n-grams_{}_filter_len_{}_fnn_{}\".format(embedding_dim, dropout, window_size, filter_length, fnn)\n",
        "# And save the model\n",
        "model.save(SST_HOME+\"DL/models/\" + name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.0763 - categorical_accuracy: 0.1931\n",
            "Epoch 2/20\n",
            " 32/202 [===>..........................] - ETA: 0s - loss: 0.0743 - categorical_accuracy: 0.2188"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1109: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy,lr\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:569: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,categorical_accuracy,lr\n",
            "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "202/202 [==============================] - 1s 5ms/step - loss: 0.0651 - categorical_accuracy: 0.1683\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.0529 - categorical_accuracy: 0.1535\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.0482 - categorical_accuracy: 0.2079\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.0397 - categorical_accuracy: 0.1881\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.0333 - categorical_accuracy: 0.1931\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.0305 - categorical_accuracy: 0.2327\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.0253 - categorical_accuracy: 0.2426\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.0212 - categorical_accuracy: 0.1683\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.0211 - categorical_accuracy: 0.1337\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.0165 - categorical_accuracy: 0.1931\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.0154 - categorical_accuracy: 0.2673\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.0150 - categorical_accuracy: 0.2376\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.0126 - categorical_accuracy: 0.1485\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.0106 - categorical_accuracy: 0.1931\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.0101 - categorical_accuracy: 0.1980\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.0099 - categorical_accuracy: 0.1683\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.0084 - categorical_accuracy: 0.1535\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.0081 - categorical_accuracy: 0.1980\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.0075 - categorical_accuracy: 0.2376\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mcSt47P389_j",
        "colab_type": "code",
        "outputId": "a37bd6b0-bdaf-4015-9068-e8dd4bb138d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(\"Applying best classifier on test data:\")\n",
        "\n",
        "predictions = model.predict(test_x_token)\n",
        "predictions = np.array([[0 if value < 0.5 else 1 for value in prediction] for prediction in predictions])\n",
        "\n",
        "# measuring performance on test set\n",
        "cr=classification_report(test_y, predictions, target_names=categories.values)\n",
        "print(cr)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Applying best classifier on test data:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "     ASP-FOR-MI       0.77      1.00      0.87        23\n",
            "      ABDOMINAL       0.75      0.27      0.40        11\n",
            "  DIETSUPP-2MOS       0.64      0.56      0.60        16\n",
            "   ADVANCED-CAD       0.54      0.81      0.65        16\n",
            "       KETO-1YR       0.00      0.00      0.00         0\n",
            " MAJOR-DIABETES       0.60      0.75      0.67        16\n",
            "          HBA1C       0.43      0.30      0.35        10\n",
            "MAKES-DECISIONS       0.93      1.00      0.97        28\n",
            "  ALCOHOL-ABUSE       0.00      0.00      0.00         1\n",
            "        ENGLISH       0.90      1.00      0.95        27\n",
            "     DRUG-ABUSE       0.00      0.00      0.00         2\n",
            "     CREATININE       0.67      0.44      0.53         9\n",
            "        MI-6MOS       0.00      0.00      0.00         2\n",
            "\n",
            "    avg / total       0.72      0.76      0.72       161\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "dnNlIl7YWSxw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#**Generating output in XML format**\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "X3xiVEPqLkF5",
        "colab_type": "code",
        "outputId": "ea6e72e8-9bb2-4af6-b902-f00cfd386b7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree\n",
        "NOT='not met'\n",
        "MET='met'\n",
        "\n",
        "#gets a idFile, a dictionary with the predictions (category, label) and the name of the classifier used.\n",
        "def outputToXML(idFile,dictPred,classifier):\n",
        "    \n",
        "    path=SST_HOME+'data/test/xml/'+idFile+'.xml'\n",
        "    \n",
        "    output=SST_HOME+'data/output/'+classifier+'/'+idFile+'.xml'\n",
        "    \n",
        "   \n",
        "    et = xml.etree.ElementTree.parse(path)\n",
        "\n",
        "    new_tag = xml.etree.ElementTree.SubElement(et.getroot(), 'TAGS')\n",
        "    \n",
        "    for cat in dictPred.keys():\n",
        "        element = xml.etree.ElementTree.SubElement(new_tag, cat)    \n",
        "        if dictPred[cat]==0:\n",
        "            element.attrib['met'] = NOT \n",
        "        else:\n",
        "            element.attrib['met'] = MET\n",
        "\n",
        "    et.write(output)\n",
        "\n",
        "#function for creating a dictionary with the categories with values 0 or 1\n",
        "def iniDictPred(labels):\n",
        "    \n",
        "    if len(labels)!=len(categories):\n",
        "        print('Warning!!!')\n",
        "        return None\n",
        "    \n",
        "    dictPred={}\n",
        "    i=0\n",
        "    \n",
        "    for x in categories:\n",
        "        dictPred[x]=labels[i]\n",
        "        i=i+1\n",
        "    return dictPred\n",
        "  \n",
        "\n",
        "print('functions to generate XML files loaded!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "functions to generate XML files loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4RxszYeCwl0Y",
        "colab_type": "code",
        "outputId": "2c6c52a4-d2a7-40b2-a45b-811db3b675ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#creates the output xml files\n",
        "dictionary = zip(idFiles, predictions)\n",
        "for obj in dictionary:\n",
        "    idFile=str(obj[0][0])\n",
        "    labels=obj[1] #gets their predictions for this file\n",
        "    dictPred=iniDictPred(labels) #creates a dictionary to join categories and labels 0,1\n",
        "    outputToXML(idFile,dictPred,\"CNN\")\n",
        "\n",
        "print('output xml files were generated!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output xml files were generated!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RGvdwKYrWloR",
        "colab_type": "code",
        "outputId": "7985a15b-23f7-43c3-b049-28ecaf7431c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "cell_type": "code",
      "source": [
        "# We move to the main folder and execute the tests\n",
        "!cd \"drive/My Drive/Colab Notebooks/CohortSelection/\" && python3 track1_eval.py data/test/gold data/output/CNN >> \"drive/My Drive/Colab Notebooks/CohortSelection/\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "******************************************* TRACK 1 ********************************************\n",
            "                      ------------ met -------------    ------ not met -------    -- overall ---\n",
            "                      Prec.   Rec.    Speci.  F(b=1)    Prec.   Rec.    F(b=1)    F(b=1)  AUC   \n",
            "           Abdominal  0.5000  0.4545  0.7368  0.4762    0.7000  0.7368  0.7179    0.5971  0.5957\n",
            "        Advanced-cad  0.8667  0.8125  0.8571  0.8387    0.8000  0.8571  0.8276    0.8331  0.8348\n",
            "       Alcohol-abuse  0.0000  0.0000  1.0000  0.0000    0.9667  1.0000  0.9831    0.4915  0.5000\n",
            "          Asp-for-mi  0.7308  0.8261  0.0000  0.7755    0.0000  0.0000  0.0000    0.3878  0.4130\n",
            "          Creatinine  0.4444  0.4444  0.7619  0.4444    0.7619  0.7619  0.7619    0.6032  0.6032\n",
            "       Dietsupp-2mos  0.6500  0.8125  0.5000  0.7222    0.7000  0.5000  0.5833    0.6528  0.6562\n",
            "          Drug-abuse  0.0000  0.0000  1.0000  0.0000    0.9333  1.0000  0.9655    0.4828  0.5000\n",
            "             English  0.9000  1.0000  0.0000  0.9474    0.0000  0.0000  0.0000    0.4737  0.5000\n",
            "               Hba1c  1.0000  0.3000  1.0000  0.4615    0.7407  1.0000  0.8511    0.6563  0.6500\n",
            "            Keto-1yr  0.0000  0.0000  1.0000  0.0000    1.0000  1.0000  1.0000    0.5000  0.5000\n",
            "      Major-diabetes  0.8000  0.7500  0.7857  0.7742    0.7333  0.7857  0.7586    0.7664  0.7679\n",
            "     Makes-decisions  0.9333  1.0000  0.0000  0.9655    0.0000  0.0000  0.0000    0.4828  0.5000\n",
            "             Mi-6mos  0.0000  0.0000  1.0000  0.0000    0.9333  1.0000  0.9655    0.4828  0.5000\n",
            "                      ------------------------------    ----------------------    --------------\n",
            "     Overall (micro)  0.7848  0.7702  0.8515  0.7774    0.8405  0.8515  0.8460    0.8117  0.8109\n",
            "     Overall (macro)  0.5250  0.4923  0.6647  0.4927    0.6361  0.6647  0.6473    0.5700  0.5785\n",
            "\n",
            "                                                    30 files found                              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5dt_5bZFXvUA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# **Generating a Keras model**\n",
        "\n",
        "In this case we still generate a model but will not train the word embeddings. Instead we will use the _\"wikipedia-pubmed-and-PMC\"_ word embeddings, which are already trained.\n",
        "\n",
        "In order to do so, we will have to perform a few additional steps before inputting the data to the network."
      ]
    },
    {
      "metadata": {
        "id": "R5-_TIkvYMpD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load the embeddings\n",
        "\n",
        "In this step, we load the word embeddings from the wikipedia, pubmed and PMC. Then we filter them adapting to the words we have in our dataset. This is, if the word appears in the pubmed we take its weights, which are set to 0 otherwise."
      ]
    },
    {
      "metadata": {
        "id": "07o9Lj0gY2lX",
        "colab_type": "code",
        "outputId": "d3d1ca4c-c47b-42cb-8351-805b591a024f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "cell_type": "code",
      "source": [
        "# seemingly gensim is not installed in google colab\n",
        "!pip install gensim"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.7.1)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.6)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
            "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (0.98)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.9.50)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.10.15)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.3)\n",
            "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.1.13)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.50 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.12.50)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.50->boto3->smart-open>=1.2.1->gensim) (0.14)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.50->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kQ_9uijiYMcm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "\n",
        "PATH_W2V = \"drive/My Drive/Colab Notebooks/CohortSelection/DL/word2vect/wikipedia-pubmed-and-PMC-w2v.bin\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sfHMKOyIc75X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Network parameters\n",
        "\n",
        "embedding_dim = 200 # The model has that dimmensions\n",
        "filter_length = 128\n",
        "window_size = 4\n",
        "dropout = 0.1\n",
        "num_classes = len(train_y[0])\n",
        "fnn = [filter_length//2, num_classes]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3nKQd17zXvGZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_W2V_model(path):\n",
        "    model = KeyedVectors.load_word2vec_format(path, binary=True)\n",
        "    print(\"Loaded W2V model\")\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VpIdt_WN_Xzy",
        "colab_type": "code",
        "outputId": "153e4f3d-8d85-4070-ef4d-b02ae3e064f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "model = load_W2V_model(PATH_W2V)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded W2V model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lvUGTAlTZFpM",
        "colab_type": "code",
        "outputId": "cf1d7004-1fe2-461d-b712-4b8cc4cc0bff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "word_index = tokenizer.word_index\n",
        "embedding_matrix = np.zeros((MAX_WORDS, embedding_dim), dtype=np.float32)\n",
        "for word, i in word_index.items():\n",
        "  if i >= MAX_WORDS:\n",
        "      break\n",
        "  if word in model:\n",
        "      # words not found in embedding index will be all-zeros.\n",
        "      embedding_matrix[i] = model[word]\n",
        "        \n",
        "print(len(embedding_matrix))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rdIVzA70hBts",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Generate the model using the embeddings\n",
        "\n",
        "Here we will generate the model by using the embeddings provided and setting that layer to not be trained."
      ]
    },
    {
      "metadata": {
        "id": "erB1izh7hZnX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Embedding, Flatten, GlobalMaxPool1D, Dropout, Conv1D\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from keras.losses import binary_crossentropy\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VO69QOlvfHGM",
        "colab_type": "code",
        "outputId": "699c6add-bbf1-4c7c-f136-84cea325d816",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "cell_type": "code",
      "source": [
        "# Generate the sequential baseline model\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_WORDS, embedding_dim, input_length=max_length, weights=[embedding_matrix], trainable=False))\n",
        "model.add(Dropout(dropout))\n",
        "model.add(Conv1D(filter_length, window_size, padding='valid', activation='relu', strides=1))\n",
        "model.add(GlobalMaxPool1D())\n",
        "model.add(Dense(filter_length//2))\n",
        "model.add(Dropout(dropout))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", \n",
        "              metrics=[\"binary_accuracy\",\n",
        "                       \"categorical_accuracy\"])\n",
        "\n",
        "# Print a summary of it.\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_15 (Embedding)     (None, 5000, 200)         1000000   \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 5000, 200)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_14 (Conv1D)           (None, 4997, 128)         102528    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_9 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 13)                845       \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 13)                0         \n",
            "=================================================================\n",
            "Total params: 1,111,629\n",
            "Trainable params: 111,629\n",
            "Non-trainable params: 1,000,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yplbB8QLhVb_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define the callbacks\n",
        "callbacks = [\n",
        "    ReduceLROnPlateau(),\n",
        "    EarlyStopping(patience=4),\n",
        "    tb.TensorBoardColabCallback(tbc)\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kCzHNjSMhjeS",
        "colab_type": "code",
        "outputId": "32919577-d51a-4e1a-9949-6b7501b0bf5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        }
      },
      "cell_type": "code",
      "source": [
        "# Fit the model and extract its data\n",
        "history = model.fit(train_x_token, train_y, epochs=20, batch_size=32, \n",
        "                    class_weight=class_weight, callbacks=callbacks,\n",
        "                    validation_data=(test_x_token, test_y))\n",
        "\n",
        "# Set a name for the model based on the tweaked parameters\n",
        "name = \"embedding_{}_dropout_{}_n-grams_{}_filter_len_{}_fnn_{}\".format(embedding_dim, dropout, window_size, filter_length, fnn)\n",
        "# And save the model\n",
        "model.save(SST_HOME+\"DL/models/\" + name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 202 samples, validate on 30 samples\n",
            "Epoch 1/20\n",
            "202/202 [==============================] - 1s 5ms/step - loss: 0.5126 - binary_accuracy: 0.7407 - categorical_accuracy: 0.3812 - val_loss: 0.4712 - val_binary_accuracy: 0.7308 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 2/20\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4523 - binary_accuracy: 0.7631 - categorical_accuracy: 0.0149 - val_loss: 0.4560 - val_binary_accuracy: 0.7795 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 3/20\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4304 - binary_accuracy: 0.7795 - categorical_accuracy: 0.0149 - val_loss: 0.4491 - val_binary_accuracy: 0.7744 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 4/20\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.4170 - binary_accuracy: 0.7928 - categorical_accuracy: 0.0099 - val_loss: 0.4453 - val_binary_accuracy: 0.7872 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 5/20\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3985 - binary_accuracy: 0.8096 - categorical_accuracy: 0.0198 - val_loss: 0.4365 - val_binary_accuracy: 0.7821 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 6/20\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3837 - binary_accuracy: 0.8294 - categorical_accuracy: 0.0149 - val_loss: 0.4408 - val_binary_accuracy: 0.7821 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 7/20\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3725 - binary_accuracy: 0.8324 - categorical_accuracy: 0.0198 - val_loss: 0.4386 - val_binary_accuracy: 0.7846 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 8/20\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3527 - binary_accuracy: 0.8458 - categorical_accuracy: 0.0149 - val_loss: 0.4340 - val_binary_accuracy: 0.7795 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 9/20\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3443 - binary_accuracy: 0.8503 - categorical_accuracy: 0.0099 - val_loss: 0.4375 - val_binary_accuracy: 0.7769 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 10/20\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3285 - binary_accuracy: 0.8629 - categorical_accuracy: 0.0198 - val_loss: 0.4372 - val_binary_accuracy: 0.7974 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 11/20\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3123 - binary_accuracy: 0.8793 - categorical_accuracy: 0.0099 - val_loss: 0.4308 - val_binary_accuracy: 0.7872 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 12/20\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.3026 - binary_accuracy: 0.8850 - categorical_accuracy: 0.0099 - val_loss: 0.4315 - val_binary_accuracy: 0.7923 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 13/20\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.2836 - binary_accuracy: 0.9014 - categorical_accuracy: 0.0149 - val_loss: 0.4278 - val_binary_accuracy: 0.8026 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 14/20\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.2655 - binary_accuracy: 0.9075 - categorical_accuracy: 0.0099 - val_loss: 0.4274 - val_binary_accuracy: 0.7846 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 15/20\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.2590 - binary_accuracy: 0.9117 - categorical_accuracy: 0.0099 - val_loss: 0.4270 - val_binary_accuracy: 0.8051 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 16/20\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.2430 - binary_accuracy: 0.9196 - categorical_accuracy: 0.0050 - val_loss: 0.4240 - val_binary_accuracy: 0.8077 - val_categorical_accuracy: 0.0000e+00\n",
            "Epoch 17/20\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.2301 - binary_accuracy: 0.9242 - categorical_accuracy: 0.0099 - val_loss: 0.4273 - val_binary_accuracy: 0.7923 - val_categorical_accuracy: 0.0333\n",
            "Epoch 18/20\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.2149 - binary_accuracy: 0.9353 - categorical_accuracy: 0.0198 - val_loss: 0.4262 - val_binary_accuracy: 0.8051 - val_categorical_accuracy: 0.0333\n",
            "Epoch 19/20\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.2024 - binary_accuracy: 0.9341 - categorical_accuracy: 0.0198 - val_loss: 0.4253 - val_binary_accuracy: 0.7974 - val_categorical_accuracy: 0.0333\n",
            "Epoch 20/20\n",
            "202/202 [==============================] - 1s 3ms/step - loss: 0.1907 - binary_accuracy: 0.9398 - categorical_accuracy: 0.0347 - val_loss: 0.4240 - val_binary_accuracy: 0.8128 - val_categorical_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "33chDQM_hlWM",
        "colab_type": "code",
        "outputId": "8347d990-3048-4df3-cb5e-11d94ee71782",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(\"Applying best classifier on test data:\")\n",
        "\n",
        "predictions = model.predict(test_x_token)\n",
        "predictions = np.array([[0 if value < 0.5 else 1 for value in prediction] for prediction in predictions])\n",
        "\n",
        "# measuring performance on test set\n",
        "cr=classification_report(test_y, predictions, target_names=categories.values)\n",
        "print(cr)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Applying best classifier on test data:\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "     ASP-FOR-MI       0.77      1.00      0.87        23\n",
            "      ABDOMINAL       0.50      0.45      0.48        11\n",
            "  DIETSUPP-2MOS       0.68      0.81      0.74        16\n",
            "   ADVANCED-CAD       0.65      0.81      0.72        16\n",
            "       KETO-1YR       0.00      0.00      0.00         0\n",
            " MAJOR-DIABETES       0.64      0.88      0.74        16\n",
            "          HBA1C       0.67      0.20      0.31        10\n",
            "MAKES-DECISIONS       0.93      1.00      0.97        28\n",
            "  ALCOHOL-ABUSE       0.00      0.00      0.00         1\n",
            "        ENGLISH       0.90      1.00      0.95        27\n",
            "     DRUG-ABUSE       0.00      0.00      0.00         2\n",
            "     CREATININE       0.62      0.56      0.59         9\n",
            "        MI-6MOS       0.00      0.00      0.00         2\n",
            "\n",
            "    avg / total       0.73      0.81      0.75       161\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
            "  'recall', 'true', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "R3OiAD9FhrVX",
        "colab_type": "code",
        "outputId": "0fc8e310-66b7-4357-c2cc-8a42e9541935",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree\n",
        "NOT='not met'\n",
        "MET='met'\n",
        "\n",
        "#gets a idFile, a dictionary with the predictions (category, label) and the name of the classifier used.\n",
        "def outputToXML(idFile,dictPred,classifier):\n",
        "    \n",
        "    path=SST_HOME+'data/test/xml/'+idFile+'.xml'\n",
        "    \n",
        "    output=SST_HOME+'data/output/'+classifier+'/'+idFile+'.xml'\n",
        "    \n",
        "   \n",
        "    et = xml.etree.ElementTree.parse(path)\n",
        "\n",
        "    new_tag = xml.etree.ElementTree.SubElement(et.getroot(), 'TAGS')\n",
        "    \n",
        "    for cat in dictPred.keys():\n",
        "        element = xml.etree.ElementTree.SubElement(new_tag, cat)    \n",
        "        if dictPred[cat]==0:\n",
        "            element.attrib['met'] = NOT \n",
        "        else:\n",
        "            element.attrib['met'] = MET\n",
        "\n",
        "    et.write(output)\n",
        "\n",
        "#function for creating a dictionary with the categories with values 0 or 1\n",
        "def iniDictPred(labels):\n",
        "    \n",
        "    if len(labels)!=len(categories):\n",
        "        print('Warning!!!')\n",
        "        return None\n",
        "    \n",
        "    dictPred={}\n",
        "    i=0\n",
        "    \n",
        "    for x in categories:\n",
        "        dictPred[x]=labels[i]\n",
        "        i=i+1\n",
        "    return dictPred\n",
        "  \n",
        "\n",
        "print('functions to generate XML files loaded!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "functions to generate XML files loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pjvqwCMwlCPb",
        "colab_type": "code",
        "outputId": "9e2c948d-0513-4216-897b-9ee4910dfd0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#creates the output xml files\n",
        "dictionary = zip(idFiles, predictions)\n",
        "for obj in dictionary:\n",
        "    idFile=str(obj[0][0])\n",
        "    labels=obj[1] #gets their predictions for this file\n",
        "    dictPred=iniDictPred(labels) #creates a dictionary to join categories and labels 0,1\n",
        "    outputToXML(idFile,dictPred,\"CNN_Embedding\")\n",
        "\n",
        "print('output xml files were generated!')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output xml files were generated!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vpQXbVE8lFr7",
        "colab_type": "code",
        "outputId": "d68d1e76-4df1-428f-c551-476591fec6f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "cell_type": "code",
      "source": [
        "# We move to the main folder and execute the tests\n",
        "!cd \"drive/My Drive/Colab Notebooks/CohortSelection/\" && python3 track1_eval.py data/test/gold data/output/CNN_Embedding"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "******************************************* TRACK 1 ********************************************\n",
            "                      ------------ met -------------    ------ not met -------    -- overall ---\n",
            "                      Prec.   Rec.    Speci.  F(b=1)    Prec.   Rec.    F(b=1)    F(b=1)  AUC   \n",
            "           Abdominal  0.5000  0.4545  0.7368  0.4762    0.7000  0.7368  0.7179    0.5971  0.5957\n",
            "        Advanced-cad  0.6500  0.8125  0.5000  0.7222    0.7000  0.5000  0.5833    0.6528  0.6562\n",
            "       Alcohol-abuse  0.0000  0.0000  1.0000  0.0000    0.9667  1.0000  0.9831    0.4915  0.5000\n",
            "          Asp-for-mi  0.7667  1.0000  0.0000  0.8679    0.0000  0.0000  0.0000    0.4340  0.5000\n",
            "          Creatinine  0.6250  0.5556  0.8571  0.5882    0.8182  0.8571  0.8372    0.7127  0.7063\n",
            "       Dietsupp-2mos  0.6842  0.8125  0.5714  0.7429    0.7273  0.5714  0.6400    0.6914  0.6920\n",
            "          Drug-abuse  0.0000  0.0000  1.0000  0.0000    0.9333  1.0000  0.9655    0.4828  0.5000\n",
            "             English  0.9000  1.0000  0.0000  0.9474    0.0000  0.0000  0.0000    0.4737  0.5000\n",
            "               Hba1c  0.6667  0.2000  0.9500  0.3077    0.7037  0.9500  0.8085    0.5581  0.5750\n",
            "            Keto-1yr  0.0000  0.0000  1.0000  0.0000    1.0000  1.0000  1.0000    0.5000  0.5000\n",
            "      Major-diabetes  0.6364  0.8750  0.4286  0.7368    0.7500  0.4286  0.5455    0.6411  0.6518\n",
            "     Makes-decisions  0.9333  1.0000  0.0000  0.9655    0.0000  0.0000  0.0000    0.4828  0.5000\n",
            "             Mi-6mos  0.0000  0.0000  1.0000  0.0000    0.9333  1.0000  0.9655    0.4828  0.5000\n",
            "                      ------------------------------    ----------------------    --------------\n",
            "     Overall (micro)  0.7558  0.8075  0.8166  0.7808    0.8578  0.8166  0.8367    0.8087  0.8120\n",
            "     Overall (macro)  0.4894  0.5162  0.6188  0.4888    0.6333  0.6188  0.6190    0.5539  0.5675\n",
            "\n",
            "                                                    30 files found                              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "L99SrARkIDkF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}